{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "GfjYoa6WmkN6",
        "q2079Qyn8Mt8",
        "ZLf6rbRglYhQ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKOTlwcmxmej"
      },
      "source": [
        "# GPT-2 Fine-Tuning Tutorial with PyTorch & Huggingface in Colab\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKGBoVwuhM4H"
      },
      "source": [
        "This is a simplified script for fine-tuning GPT2 using Hugging Face's [Transformers library](https://huggingface.co/transformers/) and PyTorch.\n",
        "\n",
        "You should understand the basics of PyTorch and how a training loop works before getting started. [This official PyTorch tutorial](https://pytorch.org/tutorials/beginner/nn_tutorial.html) serves as an excellent introduction. Familiarity with the workings of GPT2 might be useful but isn't required. The code has been written for clarity and not re-use. I'd advise refactoring it for actual projects. I've liberally taken bits from [Chris McCormick's BERT fine-tuning tutorial](https://mccormickml.com/2019/07/22/BERT-fine-tuning/), [Ian Porter's GPT2 tutorial](https://snappishproductions.com/blog/2020/03/01/chapter-9.5-text-generation-with-gpt-2-and-only-pytorch.html.html) and the [Hugging Face Language model fine-tuning script](https://huggingface.co/transformers/v2.0.0/examples.html#language-model-fine-tuning) so full credit to them. Chris' code has pretty much provided the basis for this script - you should definitely check out his [blog](https://mccormickml.com/tutorials/).\n",
        "\n",
        "I should mention what the script doesn't cover:\n",
        "\n",
        "- Using the [nlp](https://huggingface.co/nlp/) library to load in the dataset and setting up the training workflow, which looks to streamline things rather nicely.\n",
        "- [Accumulated gradients](https://medium.com/huggingface/training-larger-batches-practical-tips-on-1-gpu-multi-gpu-distributed-setups-ec88c3e51255) - this gives larger effective batch sizes than Colab allows (GPT2 is a large model, and anything more than a batch size of 2 would be enough to get a CUDA out of memory error on Colab).\n",
        "- [Freezing layers](https://github.com/huggingface/transformers/issues/1431). This is the process of only changing the parameters in selected layers, made famous by the [ULMFit](https://arxiv.org/abs/1801.06146) process.\n",
        "- [Using 'past'](https://huggingface.co/transformers/quickstart.html#using-the-past) when generating text. This takes in the previous state when generating successive items of text. I didn't need it.\n",
        "- [Tensor packing](https://snappishproductions.com/blog/2020/03/01/chapter-9.5-text-generation-with-gpt-2-and-only-pytorch.html.html). This is a neat way of fitting in as much training data in each batch. \n",
        "- [Hyperparameter search](https://discuss.huggingface.co/t/using-hyperparameter-search-in-trainer/785/10). I settled quickly on values that seemed to produce decent values, without checking if they were optimal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf3Qw77SZGbS"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NmMdkZO8R6q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "097f3d60-1b8d-4705-c412-a8a17899dc59"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCCeyhuDHdOu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d6e8221-53e3-4290-fd55-9b9ac3d8aae4"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import datetime\n",
        "from google.colab import drive\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
        "torch.manual_seed(42)\n",
        "\n",
        "from transformers import GPT2LMHeadModel,  GPT2Tokenizer, GPT2Config, GPT2LMHeadModel\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "satxtOn9CzgR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7de92017-2eda-4319-f346-9f18dcd3d8ca"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Dec 13 02:47:43 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   70C    P0    30W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfdCML6Parvv"
      },
      "source": [
        "# Create Training Set\n",
        "\n",
        "The data used to finetune the language model is a set of around 1000 DJ biographies, with the aim of generating them in the same general format and style.\n",
        "\n",
        "This data isn't public so if you want to use this script, you'll have to source your own training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EYFrNxr-TYb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc994bd7-07f7-4d33-b848-470f8f3f6508"
      },
      "source": [
        "# mount my Google Drive directory and access the training data located there\n",
        "gdrive_dir = '/content/drive/'\n",
        "# data_dir = os.path.join(gdrive_dir, \"'My Drive'\",\"'Colab Notebooks'\",\"nlp\",\"'text gen demos'\")\n",
        "\n",
        "drive.mount(gdrive_dir, force_remount=True)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_DWAMe1FopX"
      },
      "source": [
        "# copy the data to the current Colab working directory\n",
        "# !cp $data_dir/$filename ."
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA0fsB0kkO3P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "c973f696-dfe3-49bf-cdff-7abf418ea420"
      },
      "source": [
        "script = pd.read_csv('/content/drive/MyDrive/michael_project/the-office-lines - scripts.csv')\n",
        "script = script[script['speaker']=='Michael']\n",
        "script"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          id  season  episode  scene  \\\n",
              "0          1       1        1      1   \n",
              "2          3       1        1      1   \n",
              "4          5       1        1      1   \n",
              "5          6       1        1      2   \n",
              "6          7       1        1      3   \n",
              "...      ...     ...      ...    ...   \n",
              "44693  44694       7       21     49   \n",
              "44694  44695       7       21     50   \n",
              "44695  44696       7       21     51   \n",
              "59750  59751       9       23     68   \n",
              "59797  59798       9       23     84   \n",
              "\n",
              "                                               line_text  speaker  deleted  \n",
              "0      All right Jim. Your quarterlies look very good...  Michael    False  \n",
              "2      So you've come to the master for guidance? Is ...  Michael    False  \n",
              "4        All right. Well, let me show you how it's done.  Michael    False  \n",
              "5      [on the phone] Yes, I'd like to speak to your ...  Michael    False  \n",
              "6      I've, uh, I've been at Dunder Mifflin for 12 y...  Michael    False  \n",
              "...                                                  ...      ...      ...  \n",
              "44693                    Later guys. [leaves the office]  Michael    False  \n",
              "44694  Got almost everybody. So... Holly's my family ...  Michael    False  \n",
              "44695  [putting his shoes back on, talking to the cam...  Michael    False  \n",
              "59750                            That���s what she said.  Michael    False  \n",
              "59797  [crying] I feel like all my kids grew up and t...  Michael    False  \n",
              "\n",
              "[12137 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-db85eec2-08b7-45f6-b9bf-11dad26e5076\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>season</th>\n",
              "      <th>episode</th>\n",
              "      <th>scene</th>\n",
              "      <th>line_text</th>\n",
              "      <th>speaker</th>\n",
              "      <th>deleted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>All right Jim. Your quarterlies look very good...</td>\n",
              "      <td>Michael</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>So you've come to the master for guidance? Is ...</td>\n",
              "      <td>Michael</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>All right. Well, let me show you how it's done.</td>\n",
              "      <td>Michael</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>[on the phone] Yes, I'd like to speak to your ...</td>\n",
              "      <td>Michael</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>I've, uh, I've been at Dunder Mifflin for 12 y...</td>\n",
              "      <td>Michael</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44693</th>\n",
              "      <td>44694</td>\n",
              "      <td>7</td>\n",
              "      <td>21</td>\n",
              "      <td>49</td>\n",
              "      <td>Later guys. [leaves the office]</td>\n",
              "      <td>Michael</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44694</th>\n",
              "      <td>44695</td>\n",
              "      <td>7</td>\n",
              "      <td>21</td>\n",
              "      <td>50</td>\n",
              "      <td>Got almost everybody. So... Holly's my family ...</td>\n",
              "      <td>Michael</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44695</th>\n",
              "      <td>44696</td>\n",
              "      <td>7</td>\n",
              "      <td>21</td>\n",
              "      <td>51</td>\n",
              "      <td>[putting his shoes back on, talking to the cam...</td>\n",
              "      <td>Michael</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59750</th>\n",
              "      <td>59751</td>\n",
              "      <td>9</td>\n",
              "      <td>23</td>\n",
              "      <td>68</td>\n",
              "      <td>That���s what she said.</td>\n",
              "      <td>Michael</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59797</th>\n",
              "      <td>59798</td>\n",
              "      <td>9</td>\n",
              "      <td>23</td>\n",
              "      <td>84</td>\n",
              "      <td>[crying] I feel like all my kids grew up and t...</td>\n",
              "      <td>Michael</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12137 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db85eec2-08b7-45f6-b9bf-11dad26e5076')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-db85eec2-08b7-45f6-b9bf-11dad26e5076 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-db85eec2-08b7-45f6-b9bf-11dad26e5076');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "strange = script.line_text.values[-1][-11:-8]"
      ],
      "metadata": {
        "id": "i_OTtfCp_rtd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "script.line_text = script.line_text.apply(lambda x: x.replace(strange, \"'\"))"
      ],
      "metadata": {
        "id": "RJ3cyPGY-sE0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pt0dHgftPqu1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc5c5a83-69ab-4a6b-e54e-e4ca4333d9e9"
      },
      "source": [
        "len(script)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12137"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "script[\"line_size\"] = script.line_text.apply(lambda x: len(x.split()))"
      ],
      "metadata": {
        "id": "nRiDH9FttOMN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "minimun = 5\n",
        "script = script.query(f\"line_size > {minimun}\")"
      ],
      "metadata": {
        "id": "yMrvSJhHuAqG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAoKj2AaNJ8y"
      },
      "source": [
        "df = script['line_text']"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dmVnfgmwdvy",
        "outputId": "abda9033-e965-4ddb-8271-ad56f73582ae"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        All right Jim. Your quarterlies look very good...\n",
              "2        So you've come to the master for guidance? Is ...\n",
              "4          All right. Well, let me show you how it's done.\n",
              "5        [on the phone] Yes, I'd like to speak to your ...\n",
              "6        I've, uh, I've been at Dunder Mifflin for 12 y...\n",
              "                               ...                        \n",
              "44689          Okay... [crosses Jim off his list] Phyllis.\n",
              "44691    No no no, let me see. [picks up the mostly kni...\n",
              "44694    Got almost everybody. So... Holly's my family ...\n",
              "44695    [putting his shoes back on, talking to the cam...\n",
              "59797    [crying] I feel like all my kids grew up and t...\n",
              "Name: line_text, Length: 7963, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMml12FJGjPW"
      },
      "source": [
        "# GPT2 Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANJhbBwdxN-b"
      },
      "source": [
        "Although the defaults take care of this,I thought I'd show that you can specify some of the special tokens. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z474sSC6oe7A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf5a8f0c-a614-443e-86e8-3da24b557f12"
      },
      "source": [
        "# Load the GPT tokenizer.\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>') #gpt2-medium\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh0XKuDvnryn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "081559a8-90d2-4685-9a17-6651c7726de6"
      },
      "source": [
        "print(\"The max model length is {} for this model, although the actual embedding size for GPT small is 768\".format(tokenizer.model_max_length))\n",
        "print(\"The beginning of sequence token {} token has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.bos_token_id), tokenizer.bos_token_id))\n",
        "print(\"The end of sequence token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.eos_token_id), tokenizer.eos_token_id))\n",
        "print(\"The padding token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.pad_token_id), tokenizer.pad_token_id))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The max model length is 1024 for this model, although the actual embedding size for GPT small is 768\n",
            "The beginning of sequence token <|startoftext|> token has the id 50257\n",
            "The end of sequence token <|endoftext|> has the id 50256\n",
            "The padding token <|pad|> has the id 50258\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex5O1eV-Pfct"
      },
      "source": [
        "# PyTorch Datasets & Dataloaders\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lgZoOYkxZfx"
      },
      "source": [
        "GPT2 is a large model. Increasing the batch size above 2 has lead to out of memory problems. This can be mitigated by accumulating the gradients but that is out of scope here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scqrzmqhV__z"
      },
      "source": [
        "batch_size = 2"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqGMee7Isfpx"
      },
      "source": [
        "I'm using the standard PyTorch approach of loading data in using a [dataset class](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html).\n",
        "\n",
        "I'm passing in the tokenizer as an argument but normally I would  instantiate it within the class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_XJVIetKN-h"
      },
      "source": [
        "class GPT2Dataset(Dataset):\n",
        "\n",
        "  def __init__(self, txt_list, tokenizer, gpt2_type=\"gpt2\", max_length=768):\n",
        "\n",
        "    self.tokenizer = tokenizer\n",
        "    self.input_ids = []\n",
        "    self.attn_masks = []\n",
        "\n",
        "    for txt in txt_list:\n",
        "\n",
        "      encodings_dict = tokenizer('<|startoftext|>'+ txt + '<|endoftext|>', truncation=True, max_length=max_length, padding=\"max_length\")\n",
        "\n",
        "      self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
        "      self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.input_ids[idx], self.attn_masks[idx] "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89Z7aYUgpWrd"
      },
      "source": [
        "To understand how I've used the tokenizer, it's worth reading [the docs](https://huggingface.co/transformers/main_classes/tokenizer.html). I've wrapped each bio in the bos and eos tokens.\n",
        "\n",
        "Every tensor passed to the model should be the same length.\n",
        "\n",
        "If the bio is shorter than 768 tokens, it will be padded to a length of 768 using the padding token. In addition, an attention mask will be returned that needs to be passed to the model to tell it to ignore the padding tokens. \n",
        "\n",
        "If the bio is longer than 768 tokens, it will be truncated without the eos_token. This isn't a problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xza_O1_rD7yh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15ca26b8-db42-4977-8ab3-4005ba61254c"
      },
      "source": [
        "dataset = GPT2Dataset(df, tokenizer, max_length=768)\n",
        "\n",
        "# Split into training and validation sets\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7,166 training samples\n",
            "  797 validation samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0WeP5PREUuy"
      },
      "source": [
        "# Create the DataLoaders for our training and validation datasets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6TKgyUzPIQc"
      },
      "source": [
        "# Finetune GPT2 Language Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFsCTp_mporB"
      },
      "source": [
        "# I'm not really doing anything with the config buheret\n",
        "configuration = GPT2Config.from_pretrained('gpt2', output_hidden_states=False)\n",
        "\n",
        "# instantiate the model\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", config=configuration)\n",
        "\n",
        "# this step is necessary because I've added some tokens (bos_token, etc) to the embeddings\n",
        "# otherwise the tokenizer and model tensors won't match up\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "device = torch.device(\"cuda\")\n",
        "model.cuda()\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBEVY2PYSTXJ"
      },
      "source": [
        "# some parameters I cooked up that work reasonably well\n",
        "\n",
        "epochs = 3\n",
        "learning_rate = 0.00001\n",
        "warmup_steps = 1e2\n",
        "epsilon = 1e-7\n",
        "\n",
        "# this produces sample output every 100 steps\n",
        "sample_every = 100"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLs72DuMODJO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7457a803-8b36-46e7-dd32-fc1ecfa58f78"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = learning_rate,\n",
        "                  eps = epsilon\n",
        "                )"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p0upAhhRiIx"
      },
      "source": [
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "# This changes the learning rate as the training loop progresses\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = warmup_steps, \n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpt6tR83keZD"
      },
      "source": [
        "def format_time(elapsed):\n",
        "    return str(datetime.timedelta(seconds=int(round((elapsed)))))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCPohrZ-CTWu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af68a17a-7eef-4550-f47c-eb9f34dae0e3"
      },
      "source": [
        "total_t0 = time.time()\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        outputs = model(  b_input_ids,\n",
        "                          labels=b_labels, \n",
        "                          attention_mask = b_masks,\n",
        "                          token_type_ids=None\n",
        "                        )\n",
        "\n",
        "        loss = outputs[0]  \n",
        "\n",
        "        batch_loss = loss.item()\n",
        "        total_train_loss += batch_loss\n",
        "\n",
        "        # Get sample every x batches.\n",
        "        if step % sample_every == 0 and not step == 0:\n",
        "\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}. Loss: {:>5,}.   Elapsed: {:}.'.format(step, len(train_dataloader), batch_loss, elapsed))\n",
        "\n",
        "            model.eval()\n",
        "\n",
        "            sample_outputs = model.generate(\n",
        "                                    bos_token_id=random.randint(1,30000),\n",
        "                                    do_sample=True,   \n",
        "                                    top_k=50, \n",
        "                                    max_length = 200,\n",
        "                                    top_p=0.95, \n",
        "                                    num_return_sequences=1\n",
        "                                )\n",
        "            for i, sample_output in enumerate(sample_outputs):\n",
        "                  print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n",
        "            \n",
        "            model.train()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)       \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "        \n",
        "        with torch.no_grad():        \n",
        "\n",
        "            outputs  = model(b_input_ids, \n",
        "#                            token_type_ids=None, \n",
        "                             attention_mask = b_masks,\n",
        "                            labels=b_labels)\n",
        "          \n",
        "            loss = outputs[0]  \n",
        "            \n",
        "        batch_loss = loss.item()\n",
        "        total_eval_loss += batch_loss        \n",
        "\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    validation_time = format_time(time.time() - t0)    \n",
        "\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   100  of  3,583. Loss: 1.0093854665756226.   Elapsed: 0:00:51.\n",
            "0:  bipartisan\n",
            "\n",
            "\n",
            "The\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   200  of  3,583. Loss: 0.49796992540359497.   Elapsed: 0:01:42.\n",
            "0:  increasing\n",
            " it\n",
            ".\n",
            " I I,\n",
            ".\n",
            "\n",
            ".\n",
            "\n",
            ".\n",
            "\n",
            ".\n",
            "\n",
            "\n",
            "I I,\n",
            "\n",
            ".\n",
            "\n",
            ".\n",
            "\n",
            ".\n",
            "\n",
            ".\n",
            "\n",
            ".\n",
            "\n",
            ".\n",
            "\n",
            "\n",
            "I I,\n",
            "\n",
            ".\n",
            "\n",
            ".\n",
            "\n",
            ".\n",
            "\n",
            ".\n",
            "\n",
            ".\n",
            "\n",
            ".\n",
            "\n",
            ".\n",
            "\n",
            ".\n",
            "\n",
            ".\n",
            "\n",
            ".\n",
            "\n",
            ".\n",
            "\n",
            ".\n",
            "\n",
            ".\n",
            "\n",
            "\n",
            "\n",
            " I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I it, it, it, it, it it, it, it, it, it, it, it, it, it, it, it, it it, it, it, it, it, it, it,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   300  of  3,583. Loss: 0.14019913971424103.   Elapsed: 0:02:35.\n",
            "0: day it the it the it the it the it the it the it the it the it the it the the it the it the it the it the it the it the it the it the it the the it the it the it the the it the it the it the the the it the the it the the I the I the I the I the I the I the I the I the I the I the I the I the I the I the I the I the I the I the I the I the I the I the I the I the I the I the I the I the I the I the I the I the the I the I the I the I the I the I the I the I the I the I the I the I the I\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   400  of  3,583. Loss: 0.3490675687789917.   Elapsed: 0:03:27.\n",
            "0:  Hang (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n",
            " (\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   500  of  3,583. Loss: 0.11142222583293915.   Elapsed: 0:04:20.\n",
            "0:  foods ( you've got to get into it's way. you've got to get into it's way. you're getting into it's way. your way has got to have to have to have to have to have to have to have to have to have to have has to have to have to have to have to have to have to have to have to have to have to have to have to have to have to have to have to have to have to have to have to have to have to have have to have to have to have have to have have, have, have, have, have, have, have, have, have, have, have, have, have,have, have, have, have, have, have, have, have, have, have, have, have, have, have, have, have, have, have, have, have, have, have, have, have, has of have to have to\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   600  of  3,583. Loss: 0.23419290781021118.   Elapsed: 0:05:12.\n",
            "0:  trail as the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   700  of  3,583. Loss: 0.13892042636871338.   Elapsed: 0:06:05.\n",
            "0: intend\n",
            " the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   800  of  3,583. Loss: 0.14352600276470184.   Elapsed: 0:06:57.\n",
            "0:  surround\n",
            " the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   900  of  3,583. Loss: 0.08818784356117249.   Elapsed: 0:07:50.\n",
            "0:  reflex has the body, the body, the body, the body, the body, the body, the body, the body, the body, the body, the body, the body, the body, the body, the body, the body, the body, the body a person I an I an I an I an I an I an I an I a person I an I an I an I an I an I an I an I an I an I an I an I an I an I an I a person I an I an I an I an I an I an I an I an I an I an I an I an I an I an I an I an I an I an I an I an I an I an I an I an I an I an I an I an I an I an I an I an I an an I an I an I an I an a an I an I an I an I an\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,000  of  3,583. Loss: 0.1344015896320343.   Elapsed: 0:08:43.\n",
            "0:  display [ this was the same as my job and this is the same as my job. I think I'm going to start getting paid to make this. [ voice has this little voice. I'm gonna start getting paid to make this. [ voice has this little voice. The one who's working so hard is going to try to figure out how much is and what's. I'm gonna start getting paid to make this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,100  of  3,583. Loss: 0.2261628657579422.   Elapsed: 0:09:34.\n",
            "0:  pastor. person. you know? that person.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,200  of  3,583. Loss: 0.11473710089921951.   Elapsed: 0:10:24.\n",
            "0:  illicitThe problem with meis the problem with you. The world revolves around you.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,300  of  3,583. Loss: 0.11407700181007385.   Elapsed: 0:11:15.\n",
            "0:  Liberation\n",
            " and the other, where it is and the other, way is the other.\n",
            "\n",
            "\" the way that we are. The way that we are. There's nothing wrong with that.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,400  of  3,583. Loss: 0.08003459870815277.   Elapsed: 0:12:06.\n",
            "0:  Nam\n",
            " place (hope, and hope, and hope, and hope, and hope, and hope, and hope, and hope, and hope, and hope, and hope, and hope, and hope, and hope, and hope, and plan, and plan, and plan, and plan, and plan, and plan, and plan, and plan, and plan, and plan, and plan, and plan, and plan, and plan, and plan, and plan, plan, and plan, and plan, and plan, and plan, and plan, and plan, and plan, and plan, and plan, and plan, and plan, and plan, and plan, and plan, and plan, and plan, and plan, and plan, and plan, and plan, and plan, and plan, and plan, and plan, and plan, and plan, plan, and plan, and plan, and plan, and plan, and plan,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,500  of  3,583. Loss: 0.11532457172870636.   Elapsed: 0:12:59.\n",
            "0: IONIK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,600  of  3,583. Loss: 0.09601619839668274.   Elapsed: 0:13:49.\n",
            "0:  glimpse that one is the way of the world, and the way to the truth.\" world, the way the world is, is a way to the truth. And so they're using that to their advantage, using that to their advantage. And people, the people who are working as a team, the people who are team, are working as a team.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,700  of  3,583. Loss: 0.10924260318279266.   Elapsed: 0:14:41.\n",
            "0:  LaureA, yes, yes, yes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,800  of  3,583. Loss: 0.10272982716560364.   Elapsed: 0:15:31.\n",
            "0: ism\n",
            " I'm the one that is the one that I'm the one that was the one that was the one that was the one that was the one that was the one that was the one that was the one that was the one that was the one that was the one that was the one that was the one that I was the one that was the one that was the one that I was the one that was the one that was I don't make mistakes that we should make. I don't make mistakes that we shouldn't make. I don't make mistakes that we should make. I don't get. I don't get my pants. I don't get her clothes. I don't get her phone numbers. You know what I don't get her number? No. I don't get her phone number. I don't give her the credit card number. I don't give her the credit card number. I don't give her the\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,900  of  3,583. Loss: 0.058072131127119064.   Elapsed: 0:16:24.\n",
            "0: ounHe wants to get rid of, but I don't have a job. I don't have a life, I'm just happy that I have a job.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,000  of  3,583. Loss: 0.11160795390605927.   Elapsed: 0:17:15.\n",
            "0:  election of the president. I will have a great, great, great, great, great, great, great, the president of the United state of the United States. I will have a great, the president of the United States.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,100  of  3,583. Loss: 0.07884246110916138.   Elapsed: 0:18:06.\n",
            "0:  crazyI know what I am going to do. Why did you tell you all this, and how did you tell this, and how would you goabout getting this wrong?  I mean, this is something. It's an excuse.  I am asking you something.  Come on, look at what's going on...  And what's going on with this kid on this couch, thinking...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,200  of  3,583. Loss: 0.088345006108284.   Elapsed: 0:18:57.\n",
            "0:  bench.. is one of the most fun parts of playing video games. I mean, everybody plays with the wrong number, okay?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,300  of  3,583. Loss: 0.46801865100860596.   Elapsed: 0:19:48.\n",
            "0:  incorporated: A video program is being tested by the customer. [ The customer sends a video to the processor using a program that is the processor. And the program shows the results of the program, but the customer has not installed this product.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,400  of  3,583. Loss: 0.30732792615890503.   Elapsed: 0:20:39.\n",
            "0: Peter. He's right. He's right. He's going to get to know you and know how important you are to him.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,500  of  3,583. Loss: 0.08452876657247543.   Elapsed: 0:21:29.\n",
            "0: uringA little longer than you think you're staying. This morning I found out that the man that I talked to... I forgot about him!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,600  of  3,583. Loss: 0.17340998351573944.   Elapsed: 0:22:20.\n",
            "0:  reproductiveS-?-? We have to say that we're still alive, even though we have a disease and we're suffering.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,700  of  3,583. Loss: 0.2978326678276062.   Elapsed: 0:23:11.\n",
            "0:  zoneThis is the best way of trying to convince you that you need to be a team player. You need to understand why you are going here. That is probably the best way of being a team player.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,800  of  3,583. Loss: 0.251701682806015.   Elapsed: 0:24:01.\n",
            "0:  commits a it is the time to pay a $$$.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,900  of  3,583. Loss: 0.11380702257156372.   Elapsed: 0:24:52.\n",
            "0:  irony[ish, then it's] pretty cool. Yeah. It is.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,000  of  3,583. Loss: 0.1154831126332283.   Elapsed: 0:25:43.\n",
            "0:  SahDharma is so much better than any other company at this point that it should be considered a merit point if we were not in the right position when we bought it.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,100  of  3,583. Loss: 0.12462262809276581.   Elapsed: 0:26:33.\n",
            "0:  Bryan\n",
            " last night I was sitting in a club with them\n",
            "\n",
            "And they said, 'Uh oh. Okay. Here's a list of what is not right. Here's what's going to ruin your day'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,200  of  3,583. Loss: 0.10763540863990784.   Elapsed: 0:27:24.\n",
            "0:  spirits? The first of the lot of the people who came in were the men and women.\n",
            "\n",
            "If you take a look at the map I line... I think all of us are headed for the moon, but we don't need the moon. I believe that we need the moon.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,300  of  3,583. Loss: 0.41162818670272827.   Elapsed: 0:28:15.\n",
            "0:  sees an that the Internet is a good one, that it is a better place. And, again, the Internet was a good place for me.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,400  of  3,583. Loss: 0.19369523227214813.   Elapsed: 0:29:06.\n",
            "0:  hungry\n",
            " I'm not sure that the world can work out right. I know it is going to have to go through many hoops. It will need to do so many different things. But it will be a tough one.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,500  of  3,583. Loss: 0.04674316197633743.   Elapsed: 0:29:57.\n",
            "0:  PT. This is what he means, and it makes me least attractive. Like you're not my girlfriend anymore. [chuckles] I think he should take a shower, please.\n",
            "\n",
            "  Average training loss: 0.27\n",
            "  Training epoch took: 0:30:39\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.14\n",
            "  Validation took: 0:01:02\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   100  of  3,583. Loss: 0.14472758769989014.   Elapsed: 0:00:50.\n",
            "0: üWoo! He was asleep at the desk. No, I have you ready. Take your leave.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   200  of  3,583. Loss: 0.0639595091342926.   Elapsed: 0:01:41.\n",
            "0: ruceAll right. But you can't get anyhier. That's not right.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   300  of  3,583. Loss: 0.1283026784658432.   Elapsed: 0:02:31.\n",
            "0:  derivatives-in-kind, you need to be able to write these things on your own. And you need to have someone with you. So you need to write yourself. And I don't think there's a way to write your memoir for me.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   400  of  3,583. Loss: 0.09893148392438889.   Elapsed: 0:03:22.\n",
            "0: \u0019Dude, stop! You think that will be funny? Yeah. But I don't. I don't believe you.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   500  of  3,583. Loss: 0.05916859582066536.   Elapsed: 0:04:13.\n",
            "0:  rememberingWhat, is your husband trying to say that?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   600  of  3,583. Loss: 0.11775985360145569.   Elapsed: 0:05:03.\n",
            "0:  Sources. For example, let's start off by saying, well, we're going to start off with our new house, and we want us to start off with a good one. I'm going to start off with a wonderful tree. I'm going to go with a nice, old tree. I'm going to start off with a very old lady. And you know what? This is what it is. The one with the big blue stripes is going to do the math and you're going to have to prove that. And my mother would have no business letting me win. And the big blue of course is going to have to show all his qualities. And you know what? And the real one is going to go to the other end of the aisle. The lady with the big blue stripes will make him feel good. And your mother will have to prove that. [Giggles] And your wife has a lot in common. And you know what? That she's going to\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   700  of  3,583. Loss: 0.08527711778879166.   Elapsed: 0:05:56.\n",
            "0: emsI'm thinking of calling it.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   800  of  3,583. Loss: 0.04850233718752861.   Elapsed: 0:06:46.\n",
            "0: tz1 to be more precise, I'm going to give you that one, because my phone is really freaking lame. But, when the phone starts ringing you say, 'Hello, hello, hey, hello'. 'Uh, hi! Hi, Hi! Come on.' Oh no, no. Come on. Hey! Come on. [groans] Hello! Hello! Hi, hello, yes? So, um... You know who I am? I am the CEO of The Huffington Post. I am the President of The Huffington Post.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   900  of  3,583. Loss: 0.3581152558326721.   Elapsed: 0:07:37.\n",
            "0: maticTraying...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,000  of  3,583. Loss: 0.22479118406772614.   Elapsed: 0:08:28.\n",
            "0:  synd-tied, it is all very easy, and a wonderful thing to enjoy doing. And all right, my buddy, I just want to say one more thing about you. You have been my loyal friend and your friend. I love you so much. You are my nephew's friend and I love you so much. And to see you here today is just absolutely amazing. So much to see you doing. And when we talked at this event, I called you and said, that I loved you. And if you ever wanted to talk to anyone, call me, and tell me you are happy, and thank you. That doesn't sound like that to me, buddy. We both laugh. Because I mean I am smiling. [laughing] This is what it is. And so is anybody else.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,100  of  3,583. Loss: 0.056442465633153915.   Elapsed: 0:09:20.\n",
            "0:  gamTightenup, you're on the end of this. Oh! And the last two seconds of it really don't matter!  [laughs] 'Tis what they say.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,200  of  3,583. Loss: 0.06407807767391205.   Elapsed: 0:10:10.\n",
            "0:  injuryIt is just an inconvenience. You know? You should leave the house, so it could go to the toilet.  We haven't done that in a while.  I'd like to think it's not in our past.  We need you to go to the bathroom and get your makeup back.  We don't have a need for these little things right now.  We can't handle any longer a bunch of people who have the time.  I think I am getting it. So, please do not touch me.  We do want you to do some more bathing.   We are just doing our business and do not want anyone to be hurt here.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,300  of  3,583. Loss: 0.1260146200656891.   Elapsed: 0:11:02.\n",
            "0: azaA moment of love, then they will stop me.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,400  of  3,583. Loss: 0.14077003300189972.   Elapsed: 0:11:52.\n",
            "0:  membraneN, the best of the best of the best of the best of the worst of the worst of the worst, let's just leave it there. Good. A good idea, yeah. Nice ideas, too.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,500  of  3,583. Loss: 0.1300145834684372.   Elapsed: 0:12:43.\n",
            "0: ijingJeez, let's go on a date tomorrow. Let's go on a date today. I want to do a show that he never did. That's how important to us.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,600  of  3,583. Loss: 0.052649758756160736.   Elapsed: 0:13:34.\n",
            "0:  castBowser, you're dead. All right. Well, I want you guys to sit down on a chair and be kind, because we've gotta get going, and we have to find you, and I hope you'll find you as well.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,700  of  3,583. Loss: 0.12041202187538147.   Elapsed: 0:14:25.\n",
            "0:  purchNot an angel, please go on a roll.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,800  of  3,583. Loss: 0.24908781051635742.   Elapsed: 0:15:15.\n",
            "0:  shouldersI'll be fine, because everything is fine. Okay. Here, try this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,900  of  3,583. Loss: 0.6457173824310303.   Elapsed: 0:16:06.\n",
            "0:  builtA good little introduction to this game, it's pretty good. This game was a little different than some of the other games I have played. I tried to give it something different that would go along with this game. To me, the main mechanic is to drive. I hope you enjoy this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,000  of  3,583. Loss: 0.10449470579624176.   Elapsed: 0:16:56.\n",
            "0:  openlyThe idea that this would be a fun thing to do is ridiculous. I know that I'm getting a little weird.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,100  of  3,583. Loss: 0.07023079693317413.   Elapsed: 0:17:47.\n",
            "0:  haltedIt's a tough decision. What if my kids tell me that I'm a terrible person? I don't know. I'm just very bad at math.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,200  of  3,583. Loss: 0.05401377007365227.   Elapsed: 0:18:38.\n",
            "0:  NikO. The guys, he's good. Oh, okay. You know what? Everybody is talking to Michael.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,300  of  3,583. Loss: 0.13281117379665375.   Elapsed: 0:19:28.\n",
            "0:  tinCarry. The best coffee is from the oven. It just melts in our fat. It leaves a lot of juice in our fat. I have a couple of small batches and I have been looking at this recipe in a paper cup.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,400  of  3,583. Loss: 0.06622043251991272.   Elapsed: 0:20:18.\n",
            "0:  clinicalIn case of trauma, don't hesitate to contact me to discuss it with her.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,500  of  3,583. Loss: 0.21314308047294617.   Elapsed: 0:21:09.\n",
            "0: lections[in a phone phone] Alright, it's going to be alright.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,600  of  3,583. Loss: 0.14487698674201965.   Elapsed: 0:21:59.\n",
            "0: els[staging] is a bit difficult. Like, it's a little scary, but we didn't have to do that, we just had to sit and we could just relax.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,700  of  3,583. Loss: 0.11704379320144653.   Elapsed: 0:22:50.\n",
            "0: labThis is great, but I don't think we need any more of that. I think it is going to be a total disaster for us. We must get this thing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,800  of  3,583. Loss: 0.15895019471645355.   Elapsed: 0:23:40.\n",
            "0:  tripleThe next thing that goes down is I will bring some food here for my family.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,900  of  3,583. Loss: 0.08130667358636856.   Elapsed: 0:24:30.\n",
            "0: 220[to Michael] Hello, Dwight. You're on camera. Dwight's on camera. He's not on camera. Dwight's not.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,000  of  3,583. Loss: 0.08034691959619522.   Elapsed: 0:25:21.\n",
            "0:  SeeYou know... I just thought you might be the one who would appreciate a little help from some of us.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,100  of  3,583. Loss: 0.32952916622161865.   Elapsed: 0:26:11.\n",
            "0: @@Nooooo!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,200  of  3,583. Loss: 0.2417891025543213.   Elapsed: 0:27:01.\n",
            "0:  hostNo. I have no idea, what's up, Andy?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,300  of  3,583. Loss: 0.11032648384571075.   Elapsed: 0:27:52.\n",
            "0: roleA big old black dog. Very tall. Good teeth, and bad attitude toward dogs. That's why I got a great accent. Why don't you try out your new accent? Or your old one, and it's different?  Why don't you ask the guys at New York City's New York City Department of Fashion for the accent?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,400  of  3,583. Loss: 0.09206612408161163.   Elapsed: 0:28:43.\n",
            "0: iacI didn't know you, 'cause you're a very good friend of mine and the ones that I was in the business. You're all good people, even though you're not a very good salesman. Why do you think that somebody who can't sell himself into a corner gets to sell himself out?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,500  of  3,583. Loss: 0.21448847651481628.   Elapsed: 0:29:33.\n",
            "0:  LDA, Dwayne. [singing] I'm sorry, I'm sorry.  I couldn't help you.  I can't believe, I can't imagine, that you've seen me, and you know what?  It's horrible.  It looks like your body is burning.  Like, I can't believe, I'm a person, I can't believe what's happening...\n",
            "\n",
            "  Average training loss: 0.14\n",
            "  Training epoch took: 0:30:15\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.13\n",
            "  Validation took: 0:01:02\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   100  of  3,583. Loss: 0.07145819067955017.   Elapsed: 0:00:50.\n",
            "0:  ListenI am saying, 'This is a serious situation. This is an emergency. I'm asking you.' Come on.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   200  of  3,583. Loss: 0.07203811407089233.   Elapsed: 0:01:40.\n",
            "0:  dyWuh, oh, hey, hey. [laughs] Ok, yeah, this is...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   300  of  3,583. Loss: 0.23485003411769867.   Elapsed: 0:02:31.\n",
            "0:  DomesticIs that what you're saying? What are we saying? We don't want to talk about anything I say?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   400  of  3,583. Loss: 0.09562243521213531.   Elapsed: 0:03:21.\n",
            "0:  beneficiariesHe had brought the fire extinguishers up here, where they were on fire and he is dead, right?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   500  of  3,583. Loss: 0.2906090021133423.   Elapsed: 0:04:11.\n",
            "0:  TitleAll right, let's get straight to the point here. I can't say that, or that it was inappropriate. And I can't explain that to you, or to my husband who, by the way, I think is a good person, is also a very good person. But all right, let's continue. Um, here's the thing. I just want to get this out of the way of everybody thinking that that's the best thing you could possibly be thinking. Because, you know what? You're probably the best person I can be thinking about today. Because I just want to get this out of the way of everybody thinking that you're not going to do this. That's not a joke... That's not something you've ever done before.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   600  of  3,583. Loss: 0.152371346950531.   Elapsed: 0:05:03.\n",
            "0:  μAnd there are no tears in your eyes.  You have always told us, like I said, that everything must be beautiful, that everything should be perfect and that the worst of people should be punished, that we should be able to be successful together.  But when you hear that my boss has lied, and you know that I would just like to be a better man, but you know I am a woman and I just want to be able to manage all of that.  I have made my fortune, and you know what I'm going to do.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   700  of  3,583. Loss: 0.20910698175430298.   Elapsed: 0:05:54.\n",
            "0:  sellingHoney, you're going to have to give me something like 100 bucks.  You're so funny.  We should all start paying for this...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   800  of  3,583. Loss: 0.18727564811706543.   Elapsed: 0:06:45.\n",
            "0:  migrantSo I asked her what it was. I said 'Oh, you are kidding!' and she said 'Oh, no.' I went and hid her in the bushes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   900  of  3,583. Loss: 0.10364416241645813.   Elapsed: 0:07:35.\n",
            "0: ivelyI want...to talk to you.  And I want you to get some milk for me.  And I want you to do some laundry.  And I want you to do some laundry for me.  I want you to eat some hot dogs and soda and maybe some soda for me and some salad, and I want you to do some jazz so I can play piano.  I wanna tell you some stuff.  If we were in the same building.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,000  of  3,583. Loss: 0.3210252523422241.   Elapsed: 0:08:26.\n",
            "0:  orderI was surprised at the amount of interest in the paper. I don't think there is any shortage of enthusiasm in the paper. It is very important for those with financial issues...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,100  of  3,583. Loss: 0.10741280019283295.   Elapsed: 0:09:17.\n",
            "0:  VPNIt's gonna be more of a mystery than it is actually right now.  It has nothing to do with you.  There's a great deal of people in here that I love and care about.  So, if you really wanna learn about the universe here then I am totally in love with you.  If you do what the person and I did, I'm gonna be the best at it.  Whoop.  Whoop.  Whoop.  And everybody knows me, so, everybody know it.  And I'm gonna do the best I can to make you feel that way. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,200  of  3,583. Loss: 0.05732741579413414.   Elapsed: 0:10:08.\n",
            "0:  explanationA good example of an easy example.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,300  of  3,583. Loss: 0.12433882057666779.   Elapsed: 0:10:58.\n",
            "0:  BachA. Ahhh. Oh yeah, wow. [laughs]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,400  of  3,583. Loss: 0.02164212055504322.   Elapsed: 0:11:48.\n",
            "0:  folderMmm. I would be proud if I had some cheese. [hands Mmm.] [runs off]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,500  of  3,583. Loss: 0.05341848358511925.   Elapsed: 0:12:38.\n",
            "0:  buildingWell, why not? Because why not? Because we're going to put something in a drawer. So we can have a nice little drawer. And we can have some fun. And we can have a little of our own! Or whatever you like.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,600  of  3,583. Loss: 0.13684533536434174.   Elapsed: 0:13:29.\n",
            "0:  BabylonYou can't do that. [walks up to the floor] Oh wow...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,700  of  3,583. Loss: 0.045924536883831024.   Elapsed: 0:14:19.\n",
            "0: perialHey, I can tell you. You're the one who stole it. Who stole it?  It's for me.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,800  of  3,583. Loss: 0.17643263936042786.   Elapsed: 0:15:09.\n",
            "0:  rentsYou have a boss, so get over this, everybody. This is very disappointing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,900  of  3,583. Loss: 0.15056423842906952.   Elapsed: 0:16:00.\n",
            "0:  RegMentals: You know what, it's been a long, long time since I've met you here. I have so many feelings. To see you smile and have my respect, and to have you have my trust. To walk up to me, and see you smile, and talk about how much you love me, and I have just spent all my time thinking about how much you love me, and how much I love you. I have so much respect.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,000  of  3,583. Loss: 0.043903157114982605.   Elapsed: 0:16:51.\n",
            "0: olasYou know what? I have a boss who doesn't mind talking about politics. And I need her out here tonight. [gets up, gets down, walks across stage] Um, you know what? I'm going to be calling everybody, and... I am just going to get you to stand up and do something about this, because I... I want everybody around to know that... my boss's like a dreamer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,100  of  3,583. Loss: 0.14126501977443695.   Elapsed: 0:17:41.\n",
            "0:  responsesSo, you're the boss, so you know what I mean?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,200  of  3,583. Loss: 0.08764764666557312.   Elapsed: 0:18:32.\n",
            "0:  attendanceGahhhhhh!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,300  of  3,583. Loss: 0.150831401348114.   Elapsed: 0:19:22.\n",
            "0:  rigidPhew! How much money can you put together with the sales team at Amazon?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,400  of  3,583. Loss: 0.05820077285170555.   Elapsed: 0:20:12.\n",
            "0: groYes. She made it. Come on. You know what, I have a second girlfriend.  So, we'll see what she's got. And I would love to hear it...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,500  of  3,583. Loss: 0.30132806301116943.   Elapsed: 0:21:02.\n",
            "0:  GreNo we're not talking about some big fish. Just what kind of big fish can you get into?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,600  of  3,583. Loss: 0.23093822598457336.   Elapsed: 0:21:52.\n",
            "0: uraWell, thank you. I hope you're happy with the results that we have.  Maybe it's time to take a breather.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,700  of  3,583. Loss: 0.04678567126393318.   Elapsed: 0:22:42.\n",
            "0:  2020Tighten up! [starts talking, and then stops] [starts talking, and gets out of car] Oh, I don't think we have to go there. [car pulls over] Oh, it's okay.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,800  of  3,583. Loss: 0.12184421718120575.   Elapsed: 0:23:33.\n",
            "0:  chargingI'm not a murderer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,900  of  3,583. Loss: 0.061340052634477615.   Elapsed: 0:24:23.\n",
            "0:  SarBeneath his own back, I'll do it.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,000  of  3,583. Loss: 0.1526273936033249.   Elapsed: 0:25:13.\n",
            "0:  JasCarnivorous, I think that's what you said. [points to the other woman's phone]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,100  of  3,583. Loss: 0.13332615792751312.   Elapsed: 0:26:03.\n",
            "0:  permitThe thing that I had planned was for this to be done. I was going to have a party in here and there with everybody in the room. I told them that I was going to make my presentation and they wanted to know that they could have my full name and their full name. So here we are. That was the whole plan.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,200  of  3,583. Loss: 0.11483753472566605.   Elapsed: 0:26:53.\n",
            "0:  AdministratorYou did.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,300  of  3,583. Loss: 0.11064673215150833.   Elapsed: 0:27:43.\n",
            "0:  EVENTSOK. We don't have enough money to buy stuff for the office yet. Can't buy stuff here.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,400  of  3,583. Loss: 0.13721448183059692.   Elapsed: 0:28:33.\n",
            "0:  MentalThis is not what I meant.  I meant, it was.  No, it's what I meant to say.  It is what I'm trying to tell you. It is, there are some things that are in your mind that need to be reversed, you need to put them on paper, or you need to think for yourselves.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,500  of  3,583. Loss: 0.05254591628909111.   Elapsed: 0:29:24.\n",
            "0: idsAaahhh! So, now you are in charge of this whole mess?\n",
            "\n",
            "  Average training loss: 0.13\n",
            "  Training epoch took: 0:30:05\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.13\n",
            "  Validation took: 0:01:02\n",
            "\n",
            "Training complete!\n",
            "Total training took 1:34:05 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQTvJ1vRP7u4"
      },
      "source": [
        "Let's view the summary of the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O_NbXFGMukX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "be99e663-c5f0-4f4c-a757-642413d02d86"
      },
      "source": [
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Training Loss  Valid. Loss Training Time Validation Time\n",
              "epoch                                                          \n",
              "1               0.27         0.14       0:30:39         0:01:02\n",
              "2               0.14         0.13       0:30:15         0:01:02\n",
              "3               0.13         0.13       0:30:05         0:01:02"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0fd9e7da-ac86-4314-92ff-4bec46cda510\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.27</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0:30:39</td>\n",
              "      <td>0:01:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.14</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0:30:15</td>\n",
              "      <td>0:01:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.13</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0:30:05</td>\n",
              "      <td>0:01:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0fd9e7da-ac86-4314-92ff-4bec46cda510')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0fd9e7da-ac86-4314-92ff-4bec46cda510 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0fd9e7da-ac86-4314-92ff-4bec46cda510');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68xreA9JAmG5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "fb425eba-8be7-40be-aea2-dba6369082dc"
      },
      "source": [
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfjYoa6WmkN6"
      },
      "source": [
        "# Display Model Info"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PIiVlDYCtSq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "539be07e-72e4-4396-e000-af23573e68f4"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The GPT-2 model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:2]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[2:14]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-2:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The GPT-2 model has 148 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "transformer.wte.weight                                  (50259, 768)\n",
            "transformer.wpe.weight                                   (1024, 768)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "transformer.h.0.ln_1.weight                                   (768,)\n",
            "transformer.h.0.ln_1.bias                                     (768,)\n",
            "transformer.h.0.attn.c_attn.weight                       (768, 2304)\n",
            "transformer.h.0.attn.c_attn.bias                             (2304,)\n",
            "transformer.h.0.attn.c_proj.weight                        (768, 768)\n",
            "transformer.h.0.attn.c_proj.bias                              (768,)\n",
            "transformer.h.0.ln_2.weight                                   (768,)\n",
            "transformer.h.0.ln_2.bias                                     (768,)\n",
            "transformer.h.0.mlp.c_fc.weight                          (768, 3072)\n",
            "transformer.h.0.mlp.c_fc.bias                                (3072,)\n",
            "transformer.h.0.mlp.c_proj.weight                        (3072, 768)\n",
            "transformer.h.0.mlp.c_proj.bias                               (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "transformer.ln_f.weight                                       (768,)\n",
            "transformer.ln_f.bias                                         (768,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2079Qyn8Mt8"
      },
      "source": [
        "# Saving & Loading Fine-Tuned Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ulTWaOr8QNY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2659ffda-477a-4ab6-98d7-0374920f74c7"
      },
      "source": [
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = '/content/drive/MyDrive/michael_project/model_save/caio'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to /content/drive/MyDrive/michael_project/model_save/caio\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/michael_project/model_save/caio/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/michael_project/model_save/caio/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/michael_project/model_save/caio/vocab.json',\n",
              " '/content/drive/MyDrive/michael_project/model_save/caio/merges.txt',\n",
              " '/content/drive/MyDrive/michael_project/model_save/caio/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqMzI3VTCZo5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6f5274a-ae67-4f10-c8d2-8430ce2adcb2"
      },
      "source": [
        "!ls -l --block-size=K ./model_save/"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access './model_save/': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WUFUIQ8Cu8D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9998b44c-3037-4227-d2e1-0acfbcbf9089"
      },
      "source": [
        "!ls -l --block-size=M ./model_save/pytorch_model.bin"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access './model_save/pytorch_model.bin': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxlZsafTC-V5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dddf95a2-559e-4596-8c5d-c07c7cd9065b"
      },
      "source": [
        "# Copy the model files to a directory in your Google Drive.\n",
        "# !cp -r ./model_save/ $data_dir\n",
        "\n",
        "# # Load a trained model and vocabulary that you have fine-tuned\n",
        "model = GPT2LMHeadModel.from_pretrained(output_dir)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(output_dir)\n",
        "model.to(device)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50259, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50259, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLf6rbRglYhQ"
      },
      "source": [
        "# Generate Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4XhewaV93-_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de24f1a1-9c05-46d9-c279-524ca4bfe2e3"
      },
      "source": [
        "model.eval()\n",
        "\n",
        "prompt = \"<|startoftext|>\"\n",
        "\n",
        "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "generated = generated.to(device)\n",
        "\n",
        "print(generated)\n",
        "\n",
        "sample_outputs = model.generate(\n",
        "                                generated, \n",
        "                                #bos_token_id=random.randint(1,30000),\n",
        "                                do_sample=True,   \n",
        "                                top_k=50, \n",
        "                                max_length = 300,\n",
        "                                top_p=0.95, \n",
        "                                num_return_sequences=10\n",
        "                                )\n",
        "\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[50257]], device='cuda:0')\n",
            "0: We should be using the phone for surveillance.\n",
            "\n",
            "\n",
            "1: Dwight? [to Andy]\n",
            "\n",
            "\n",
            "2: Oh, I'm sorry, but that's not what I said... Okay, uh, it's not my fault, that's what you said.\n",
            "\n",
            "\n",
            "3: Ow, who did you think you were in the right, I want to say, with...\n",
            "\n",
            "\n",
            "4: [mock sighs] I hate them.\n",
            "\n",
            "\n",
            "5: Yes, sir. Aaaaah. That's a very nice compliment.\n",
            "\n",
            "\n",
            "6: [phone rings] Hey, Pam.  Is somebody else here?  Yeah, we've got a problem.  Is somebody else?\n",
            "\n",
            "\n",
            "7: No, no. No, no.  You, it wasn't my fault.  It was me.  I knew exactly who did it.  I knew where he was from.  He was on TV, so who knows?  Who does it. [walks out onto the kitchen porch] Yeah, I understand what you're saying.  You didn't stop the traffic.\n",
            "\n",
            "\n",
            "8: No. I am not going to take that. [points to a note on Michael's desk and holds it in his lap and walks away. There is a flash of fire from that point]\n",
            "\n",
            "\n",
            "9: Yes.  I do not.  This is a joke, Dwight.  It is an  accident of childhood.  I was trying to make fun of Dwight, because I did not think he would ever leave the school.  The only thing that I ever thought would happen to Dwight was if, during the summer, he would have been out on his way to the lake.  My first thought was to tell him, oh, 'I can't come, I can't come.'  But Dwight, he's been drinking all his life.  He's been around the lake.  He's been smoking cigarettes.  He's taken up a lot of college.  He will not leave me.  And it's going to happen.  [takes out a cigarette] Oh, Dwight.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4LrX5H-0nAU"
      },
      "source": [
        "These aren't bad at all!\n"
      ]
    }
  ]
}