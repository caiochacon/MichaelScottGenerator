{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6b3f12a826c44e1a8eef298c1f8d22be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4f56524fc38e4243a83451d56b1558e5",
              "IPY_MODEL_10975d5894764e35a1d130937a257c26",
              "IPY_MODEL_0bed7072b7d047eb93e0b847cdcb4f9c"
            ],
            "layout": "IPY_MODEL_84516cccd42a425f9fd41a6a382058d5"
          }
        },
        "4f56524fc38e4243a83451d56b1558e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d905f8b2cad41379a2e0f45a9d6e283",
            "placeholder": "​",
            "style": "IPY_MODEL_5141bf8e80ef4560975b6424fbf80553",
            "value": "Downloading: 100%"
          }
        },
        "10975d5894764e35a1d130937a257c26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eec88bbf16064a8db54b7a392ad0a67d",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_40960cf3193f4ec6a787e740ba42978c",
            "value": 1042301
          }
        },
        "0bed7072b7d047eb93e0b847cdcb4f9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbd3ca0c62d84a468722e7f8182848f6",
            "placeholder": "​",
            "style": "IPY_MODEL_2c7ec50c7f874e67b8ac4f7c67e6a2ae",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 1.66MB/s]"
          }
        },
        "84516cccd42a425f9fd41a6a382058d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d905f8b2cad41379a2e0f45a9d6e283": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5141bf8e80ef4560975b6424fbf80553": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eec88bbf16064a8db54b7a392ad0a67d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40960cf3193f4ec6a787e740ba42978c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bbd3ca0c62d84a468722e7f8182848f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c7ec50c7f874e67b8ac4f7c67e6a2ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6ded39fb97345adbc5347c97c2a24ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e73dbe77b192471083a6b18a544116dd",
              "IPY_MODEL_26654da6a98042cb95552c17e3fec1ed",
              "IPY_MODEL_78331f5d2c804dc29ce87c7fb97ac1ba"
            ],
            "layout": "IPY_MODEL_02325866003648fda45f43ce29fc5037"
          }
        },
        "e73dbe77b192471083a6b18a544116dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d8a423d259f42afaf59d672a2713ac8",
            "placeholder": "​",
            "style": "IPY_MODEL_de0c8ec7a729451891c1d85d38463507",
            "value": "Downloading: 100%"
          }
        },
        "26654da6a98042cb95552c17e3fec1ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75f0b9daa80c4618ab7728ade523f620",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f173488a8e474dd38fc25796e12a0990",
            "value": 456318
          }
        },
        "78331f5d2c804dc29ce87c7fb97ac1ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a70612b963e84160a4bdddf628d3f604",
            "placeholder": "​",
            "style": "IPY_MODEL_2b63287ea12c47e8a5d5f303af9033b4",
            "value": " 456k/456k [00:00&lt;00:00, 487kB/s]"
          }
        },
        "02325866003648fda45f43ce29fc5037": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d8a423d259f42afaf59d672a2713ac8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de0c8ec7a729451891c1d85d38463507": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75f0b9daa80c4618ab7728ade523f620": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f173488a8e474dd38fc25796e12a0990": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a70612b963e84160a4bdddf628d3f604": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b63287ea12c47e8a5d5f303af9033b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eda9d5c09cb0482189db79b79b321008": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d2a13edf1df542a9bcbbb5d720999610",
              "IPY_MODEL_5c9c3fc20d5c41b586c8b7bfc51177d7",
              "IPY_MODEL_b2ba488bb554434fa962944807477e66"
            ],
            "layout": "IPY_MODEL_2790d1488a044c9289720f2393059c28"
          }
        },
        "d2a13edf1df542a9bcbbb5d720999610": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4ac8f4070a44c3f8d82c05564a48a9a",
            "placeholder": "​",
            "style": "IPY_MODEL_e58aff9cf13843f2aedcf11b28de1bbc",
            "value": "Downloading: 100%"
          }
        },
        "5c9c3fc20d5c41b586c8b7bfc51177d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f68c24ab87174c6bb35d82cd25daa1ea",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_32fb05dbae6b44da92d655ece21dd9f1",
            "value": 665
          }
        },
        "b2ba488bb554434fa962944807477e66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a1011579cdf46ca8eea1e1f6e8f891e",
            "placeholder": "​",
            "style": "IPY_MODEL_732eabb11c4d4b13a84264b8f687b07e",
            "value": " 665/665 [00:00&lt;00:00, 15.0kB/s]"
          }
        },
        "2790d1488a044c9289720f2393059c28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4ac8f4070a44c3f8d82c05564a48a9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e58aff9cf13843f2aedcf11b28de1bbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f68c24ab87174c6bb35d82cd25daa1ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32fb05dbae6b44da92d655ece21dd9f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1a1011579cdf46ca8eea1e1f6e8f891e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "732eabb11c4d4b13a84264b8f687b07e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKOTlwcmxmej"
      },
      "source": [
        "# GPT-2 Fine-Tuning Tutorial with PyTorch & Huggingface in Colab\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKGBoVwuhM4H"
      },
      "source": [
        "This is a simplified script for fine-tuning GPT2 using Hugging Face's [Transformers library](https://huggingface.co/transformers/) and PyTorch.\n",
        "\n",
        "You should understand the basics of PyTorch and how a training loop works before getting started. [This official PyTorch tutorial](https://pytorch.org/tutorials/beginner/nn_tutorial.html) serves as an excellent introduction. Familiarity with the workings of GPT2 might be useful but isn't required. The code has been written for clarity and not re-use. I'd advise refactoring it for actual projects. I've liberally taken bits from [Chris McCormick's BERT fine-tuning tutorial](https://mccormickml.com/2019/07/22/BERT-fine-tuning/), [Ian Porter's GPT2 tutorial](https://snappishproductions.com/blog/2020/03/01/chapter-9.5-text-generation-with-gpt-2-and-only-pytorch.html.html) and the [Hugging Face Language model fine-tuning script](https://huggingface.co/transformers/v2.0.0/examples.html#language-model-fine-tuning) so full credit to them. Chris' code has pretty much provided the basis for this script - you should definitely check out his [blog](https://mccormickml.com/tutorials/).\n",
        "\n",
        "I should mention what the script doesn't cover:\n",
        "\n",
        "- Using the [nlp](https://huggingface.co/nlp/) library to load in the dataset and setting up the training workflow, which looks to streamline things rather nicely.\n",
        "- [Accumulated gradients](https://medium.com/huggingface/training-larger-batches-practical-tips-on-1-gpu-multi-gpu-distributed-setups-ec88c3e51255) - this gives larger effective batch sizes than Colab allows (GPT2 is a large model, and anything more than a batch size of 2 would be enough to get a CUDA out of memory error on Colab).\n",
        "- [Freezing layers](https://github.com/huggingface/transformers/issues/1431). This is the process of only changing the parameters in selected layers, made famous by the [ULMFit](https://arxiv.org/abs/1801.06146) process.\n",
        "- [Using 'past'](https://huggingface.co/transformers/quickstart.html#using-the-past) when generating text. This takes in the previous state when generating successive items of text. I didn't need it.\n",
        "- [Tensor packing](https://snappishproductions.com/blog/2020/03/01/chapter-9.5-text-generation-with-gpt-2-and-only-pytorch.html.html). This is a neat way of fitting in as much training data in each batch. \n",
        "- [Hyperparameter search](https://discuss.huggingface.co/t/using-hyperparameter-search-in-trainer/785/10). I settled quickly on values that seemed to produce decent values, without checking if they were optimal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf3Qw77SZGbS"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NmMdkZO8R6q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bc5a700-1f05-456f-eb47-51f00bf38622"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 10.1 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 52.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 58.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCCeyhuDHdOu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bac3c4df-68aa-4763-d747-2d2899630ac7"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import datetime\n",
        "from google.colab import drive\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
        "torch.manual_seed(42)\n",
        "\n",
        "from transformers import GPT2LMHeadModel,  GPT2Tokenizer, GPT2Config, GPT2LMHeadModel\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "satxtOn9CzgR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96a0f59f-1eb2-4415-e214-525566e0b197"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Dec 13 02:28:04 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P0    25W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfdCML6Parvv"
      },
      "source": [
        "# Create Training Set\n",
        "\n",
        "The data used to finetune the language model is a set of around 1000 DJ biographies, with the aim of generating them in the same general format and style.\n",
        "\n",
        "This data isn't public so if you want to use this script, you'll have to source your own training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EYFrNxr-TYb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a063d1b-d9ec-4c23-eaee-86c8f358593f"
      },
      "source": [
        "# mount my Google Drive directory and access the training data located there\n",
        "gdrive_dir = '/content/drive/'\n",
        "# data_dir = os.path.join(gdrive_dir, \"'My Drive'\",\"'Colab Notebooks'\",\"nlp\",\"'text gen demos'\")\n",
        "\n",
        "drive.mount(gdrive_dir, force_remount=True)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_DWAMe1FopX"
      },
      "source": [
        "# copy the data to the current Colab working directory\n",
        "# !cp $data_dir/$filename ."
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA0fsB0kkO3P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "d0e95a51-66ed-43a0-cbf6-bb60dbe6c622"
      },
      "source": [
        "script = pd.read_csv('/content/drive/MyDrive/the-office-lines - scripts.csv')\n",
        "script = script[script['speaker']=='Michael']\n",
        "script"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          id  season  episode  scene  \\\n",
              "0          1       1        1      1   \n",
              "2          3       1        1      1   \n",
              "4          5       1        1      1   \n",
              "5          6       1        1      2   \n",
              "6          7       1        1      3   \n",
              "...      ...     ...      ...    ...   \n",
              "44693  44694       7       21     49   \n",
              "44694  44695       7       21     50   \n",
              "44695  44696       7       21     51   \n",
              "59750  59751       9       23     68   \n",
              "59797  59798       9       23     84   \n",
              "\n",
              "                                               line_text  speaker  deleted  \n",
              "0      All right Jim. Your quarterlies look very good...  Michael    False  \n",
              "2      So you've come to the master for guidance? Is ...  Michael    False  \n",
              "4        All right. Well, let me show you how it's done.  Michael    False  \n",
              "5      [on the phone] Yes, I'd like to speak to your ...  Michael    False  \n",
              "6      I've, uh, I've been at Dunder Mifflin for 12 y...  Michael    False  \n",
              "...                                                  ...      ...      ...  \n",
              "44693                    Later guys. [leaves the office]  Michael    False  \n",
              "44694  Got almost everybody. So... Holly's my family ...  Michael    False  \n",
              "44695  [putting his shoes back on, talking to the cam...  Michael    False  \n",
              "59750                            That���s what she said.  Michael    False  \n",
              "59797  [crying] I feel like all my kids grew up and t...  Michael    False  \n",
              "\n",
              "[12137 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6c0f0bca-9c1b-4bc4-b404-23ff1916b302\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>season</th>\n",
              "      <th>episode</th>\n",
              "      <th>scene</th>\n",
              "      <th>line_text</th>\n",
              "      <th>speaker</th>\n",
              "      <th>deleted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>All right Jim. Your quarterlies look very good...</td>\n",
              "      <td>Michael</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>So you've come to the master for guidance? Is ...</td>\n",
              "      <td>Michael</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>All right. Well, let me show you how it's done.</td>\n",
              "      <td>Michael</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>[on the phone] Yes, I'd like to speak to your ...</td>\n",
              "      <td>Michael</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>I've, uh, I've been at Dunder Mifflin for 12 y...</td>\n",
              "      <td>Michael</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44693</th>\n",
              "      <td>44694</td>\n",
              "      <td>7</td>\n",
              "      <td>21</td>\n",
              "      <td>49</td>\n",
              "      <td>Later guys. [leaves the office]</td>\n",
              "      <td>Michael</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44694</th>\n",
              "      <td>44695</td>\n",
              "      <td>7</td>\n",
              "      <td>21</td>\n",
              "      <td>50</td>\n",
              "      <td>Got almost everybody. So... Holly's my family ...</td>\n",
              "      <td>Michael</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44695</th>\n",
              "      <td>44696</td>\n",
              "      <td>7</td>\n",
              "      <td>21</td>\n",
              "      <td>51</td>\n",
              "      <td>[putting his shoes back on, talking to the cam...</td>\n",
              "      <td>Michael</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59750</th>\n",
              "      <td>59751</td>\n",
              "      <td>9</td>\n",
              "      <td>23</td>\n",
              "      <td>68</td>\n",
              "      <td>That���s what she said.</td>\n",
              "      <td>Michael</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59797</th>\n",
              "      <td>59798</td>\n",
              "      <td>9</td>\n",
              "      <td>23</td>\n",
              "      <td>84</td>\n",
              "      <td>[crying] I feel like all my kids grew up and t...</td>\n",
              "      <td>Michael</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12137 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c0f0bca-9c1b-4bc4-b404-23ff1916b302')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6c0f0bca-9c1b-4bc4-b404-23ff1916b302 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6c0f0bca-9c1b-4bc4-b404-23ff1916b302');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "strange = script.line_text.values[-1][-11:-8]"
      ],
      "metadata": {
        "id": "i_OTtfCp_rtd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "script.line_text = script.line_text.apply(lambda x: x.replace(strange, \"'\"))"
      ],
      "metadata": {
        "id": "RJ3cyPGY-sE0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pt0dHgftPqu1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dad7e04-649c-46b3-8a64-de7b4eff347c"
      },
      "source": [
        "len(script)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12137"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "script[\"line_size\"] = script.line_text.apply(lambda x: len(x.split()))"
      ],
      "metadata": {
        "id": "nRiDH9FttOMN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "minimun = 5\n",
        "script = script.query(f\"line_size > {minimun}\")"
      ],
      "metadata": {
        "id": "yMrvSJhHuAqG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAoKj2AaNJ8y"
      },
      "source": [
        "df = script['line_text']"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dmVnfgmwdvy",
        "outputId": "c411814e-f540-46fa-e4e1-a55952bdaf30"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        All right Jim. Your quarterlies look very good...\n",
              "2        So you've come to the master for guidance? Is ...\n",
              "4          All right. Well, let me show you how it's done.\n",
              "5        [on the phone] Yes, I'd like to speak to your ...\n",
              "6        I've, uh, I've been at Dunder Mifflin for 12 y...\n",
              "                               ...                        \n",
              "44689          Okay... [crosses Jim off his list] Phyllis.\n",
              "44691    No no no, let me see. [picks up the mostly kni...\n",
              "44694    Got almost everybody. So... Holly's my family ...\n",
              "44695    [putting his shoes back on, talking to the cam...\n",
              "59797    [crying] I feel like all my kids grew up and t...\n",
              "Name: line_text, Length: 7963, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMml12FJGjPW"
      },
      "source": [
        "# GPT2 Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANJhbBwdxN-b"
      },
      "source": [
        "Although the defaults take care of this,I thought I'd show that you can specify some of the special tokens. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z474sSC6oe7A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130,
          "referenced_widgets": [
            "6b3f12a826c44e1a8eef298c1f8d22be",
            "4f56524fc38e4243a83451d56b1558e5",
            "10975d5894764e35a1d130937a257c26",
            "0bed7072b7d047eb93e0b847cdcb4f9c",
            "84516cccd42a425f9fd41a6a382058d5",
            "0d905f8b2cad41379a2e0f45a9d6e283",
            "5141bf8e80ef4560975b6424fbf80553",
            "eec88bbf16064a8db54b7a392ad0a67d",
            "40960cf3193f4ec6a787e740ba42978c",
            "bbd3ca0c62d84a468722e7f8182848f6",
            "2c7ec50c7f874e67b8ac4f7c67e6a2ae",
            "a6ded39fb97345adbc5347c97c2a24ef",
            "e73dbe77b192471083a6b18a544116dd",
            "26654da6a98042cb95552c17e3fec1ed",
            "78331f5d2c804dc29ce87c7fb97ac1ba",
            "02325866003648fda45f43ce29fc5037",
            "8d8a423d259f42afaf59d672a2713ac8",
            "de0c8ec7a729451891c1d85d38463507",
            "75f0b9daa80c4618ab7728ade523f620",
            "f173488a8e474dd38fc25796e12a0990",
            "a70612b963e84160a4bdddf628d3f604",
            "2b63287ea12c47e8a5d5f303af9033b4",
            "eda9d5c09cb0482189db79b79b321008",
            "d2a13edf1df542a9bcbbb5d720999610",
            "5c9c3fc20d5c41b586c8b7bfc51177d7",
            "b2ba488bb554434fa962944807477e66",
            "2790d1488a044c9289720f2393059c28",
            "e4ac8f4070a44c3f8d82c05564a48a9a",
            "e58aff9cf13843f2aedcf11b28de1bbc",
            "f68c24ab87174c6bb35d82cd25daa1ea",
            "32fb05dbae6b44da92d655ece21dd9f1",
            "1a1011579cdf46ca8eea1e1f6e8f891e",
            "732eabb11c4d4b13a84264b8f687b07e"
          ]
        },
        "outputId": "13cf9b6e-0d0b-42b8-bf22-484d76ff6f05"
      },
      "source": [
        "# Load the GPT tokenizer.\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>') #gpt2\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b3f12a826c44e1a8eef298c1f8d22be"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a6ded39fb97345adbc5347c97c2a24ef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eda9d5c09cb0482189db79b79b321008"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh0XKuDvnryn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ad945a5-9de1-4eac-93a5-3ea870dc4433"
      },
      "source": [
        "print(\"The max model length is {} for this model, although the actual embedding size for GPT small is 768\".format(tokenizer.model_max_length))\n",
        "print(\"The beginning of sequence token {} token has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.bos_token_id), tokenizer.bos_token_id))\n",
        "print(\"The end of sequence token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.eos_token_id), tokenizer.eos_token_id))\n",
        "print(\"The padding token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.pad_token_id), tokenizer.pad_token_id))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The max model length is 1024 for this model, although the actual embedding size for GPT small is 768\n",
            "The beginning of sequence token <|startoftext|> token has the id 50257\n",
            "The end of sequence token <|endoftext|> has the id 50256\n",
            "The padding token <|pad|> has the id 50258\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex5O1eV-Pfct"
      },
      "source": [
        "# PyTorch Datasets & Dataloaders\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lgZoOYkxZfx"
      },
      "source": [
        "GPT2 is a large model. Increasing the batch size above 2 has lead to out of memory problems. This can be mitigated by accumulating the gradients but that is out of scope here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scqrzmqhV__z"
      },
      "source": [
        "batch_size = 2"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqGMee7Isfpx"
      },
      "source": [
        "I'm using the standard PyTorch approach of loading data in using a [dataset class](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html).\n",
        "\n",
        "I'm passing in the tokenizer as an argument but normally I would  instantiate it within the class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_XJVIetKN-h"
      },
      "source": [
        "class GPT2Dataset(Dataset):\n",
        "\n",
        "  def __init__(self, txt_list, tokenizer, gpt2_type=\"gpt2\", max_length=768):\n",
        "\n",
        "    self.tokenizer = tokenizer\n",
        "    self.input_ids = []\n",
        "    self.attn_masks = []\n",
        "\n",
        "    for txt in txt_list:\n",
        "\n",
        "      encodings_dict = tokenizer('<|startoftext|>'+ txt + '<|endoftext|>', truncation=True, max_length=max_length, padding=\"max_length\")\n",
        "\n",
        "      self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
        "      self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.input_ids[idx], self.attn_masks[idx] "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89Z7aYUgpWrd"
      },
      "source": [
        "To understand how I've used the tokenizer, it's worth reading [the docs](https://huggingface.co/transformers/main_classes/tokenizer.html). I've wrapped each bio in the bos and eos tokens.\n",
        "\n",
        "Every tensor passed to the model should be the same length.\n",
        "\n",
        "If the bio is shorter than 768 tokens, it will be padded to a length of 768 using the padding token. In addition, an attention mask will be returned that needs to be passed to the model to tell it to ignore the padding tokens. \n",
        "\n",
        "If the bio is longer than 768 tokens, it will be truncated without the eos_token. This isn't a problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xza_O1_rD7yh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b48ab3db-852a-4607-9d61-583985aea2d2"
      },
      "source": [
        "dataset = GPT2Dataset(df, tokenizer, max_length=768)\n",
        "\n",
        "# Split into training and validation sets\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7,166 training samples\n",
            "  797 validation samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0WeP5PREUuy"
      },
      "source": [
        "# Create the DataLoaders for our training and validation datasets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6TKgyUzPIQc"
      },
      "source": [
        "# Finetune GPT2 Language Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFsCTp_mporB"
      },
      "source": [
        "# I'm not really doing anything with the config buheret\n",
        "configuration = GPT2Config.from_pretrained('gpt2', output_hidden_states=False)\n",
        "\n",
        "# instantiate the model\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", config=configuration)\n",
        "\n",
        "# this step is necessary because I've added some tokens (bos_token, etc) to the embeddings\n",
        "# otherwise the tokenizer and model tensors won't match up\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "device = torch.device(\"cuda\")\n",
        "model.cuda()\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 45\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBEVY2PYSTXJ"
      },
      "source": [
        "# some parameters I cooked up that work reasonably well\n",
        "\n",
        "epochs = 3\n",
        "learning_rate = 0.0001\n",
        "warmup_steps = 1e2\n",
        "epsilon = 1e-8\n",
        "\n",
        "# this produces sample output every 100 steps\n",
        "sample_every = 100"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLs72DuMODJO"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = learning_rate,\n",
        "                  eps = epsilon\n",
        "                )"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p0upAhhRiIx"
      },
      "source": [
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "# This changes the learning rate as the training loop progresses\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = warmup_steps, \n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpt6tR83keZD"
      },
      "source": [
        "def format_time(elapsed):\n",
        "    return str(datetime.timedelta(seconds=int(round((elapsed)))))"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCPohrZ-CTWu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfd4fb32-da79-4619-80a8-c1943adb964d"
      },
      "source": [
        "total_t0 = time.time()\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        outputs = model(  b_input_ids,\n",
        "                          labels=b_labels, \n",
        "                          attention_mask = b_masks,\n",
        "                          token_type_ids=None\n",
        "                        )\n",
        "\n",
        "        loss = outputs[0]  \n",
        "\n",
        "        batch_loss = loss.item()\n",
        "        total_train_loss += batch_loss\n",
        "\n",
        "        # Get sample every x batches.\n",
        "        if step % sample_every == 0 and not step == 0:\n",
        "\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}. Loss: {:>5,}.   Elapsed: {:}.'.format(step, len(train_dataloader), batch_loss, elapsed))\n",
        "\n",
        "            model.eval()\n",
        "\n",
        "            sample_outputs = model.generate(\n",
        "                                    bos_token_id=random.randint(1,30000),\n",
        "                                    do_sample=True,   \n",
        "                                    top_k=50, \n",
        "                                    max_length = 200,\n",
        "                                    top_p=0.95, \n",
        "                                    num_return_sequences=1\n",
        "                                )\n",
        "            for i, sample_output in enumerate(sample_outputs):\n",
        "                  print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n",
        "            \n",
        "            model.train()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)       \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "        \n",
        "        with torch.no_grad():        \n",
        "\n",
        "            outputs  = model(b_input_ids, \n",
        "#                            token_type_ids=None, \n",
        "                             attention_mask = b_masks,\n",
        "                            labels=b_labels)\n",
        "          \n",
        "            loss = outputs[0]  \n",
        "            \n",
        "        batch_loss = loss.item()\n",
        "        total_eval_loss += batch_loss        \n",
        "\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    validation_time = format_time(time.time() - t0)    \n",
        "\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   100  of  3,583. Loss: 0.2030961960554123.   Elapsed: 0:00:50.\n",
            "0:  DiscW, I can't do it. There's something you did it. That's right in your face.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   200  of  3,583. Loss: 0.08125189691781998.   Elapsed: 0:01:39.\n",
            "0:  primP. Oh, good. What'd you say?\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   300  of  3,583. Loss: 0.19914110004901886.   Elapsed: 0:02:29.\n",
            "0:  DaveWhat's in your portfolio?  Good.  You're the sort of guy who takes the picture of someone else and goes to the very end, with his camera.  You're not in the company of any sort of company.  You have very distinct personalities.  You don't make mistakes.  You have no special talents and you don't need to be a jerk.  You have good work ethic and you don't need to be an idiot to be successful.  You don't need to be a jerk.  And you don't need to be a jerk.  Just stay with your feet.  Just stay with your feet.  Good work ethic. I'm going to need you to tell me a little bit more about the people I work for.  You're...  They are...  You have very different styles of thinking.  What you can do, you know.  I will tell you a story about a group of friends that you're working for\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   400  of  3,583. Loss: 0.05423016846179962.   Elapsed: 0:03:20.\n",
            "0:  ballotI agree, but this is not my country. This is not your country. This is not my homeland. This is not the place where you live. It is not our country. It is not your place. And not at the behest of any agency or anyone in our government.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   500  of  3,583. Loss: 0.30784866213798523.   Elapsed: 0:04:10.\n",
            "0:  attWell, I know this is not a big secret, but I'm going to keep this secret.  You know, this is all about you...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   600  of  3,583. Loss: 0.09359785169363022.   Elapsed: 0:04:59.\n",
            "0: intonNah! Okay. It's only because I haven't used her.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   700  of  3,583. Loss: 0.06423996388912201.   Elapsed: 0:05:48.\n",
            "0:  ChampionNo, no. No. So I guess we could do the same, yeah. [holds up, turns back down]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   800  of  3,583. Loss: 0.1313079595565796.   Elapsed: 0:06:37.\n",
            "0:  2Good, he had a great time. Oh, here we go.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   900  of  3,583. Loss: 0.1329190582036972.   Elapsed: 0:07:27.\n",
            "0:  FireOkay. I'll have an order for lunch.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,000  of  3,583. Loss: 0.08504350483417511.   Elapsed: 0:08:16.\n",
            "0: engersThis is a pretty cool guy that I got my copy of.  He's like the guy that a woman in a hospital has to get an airfare in order to get to the hospital.  He wants her to go to the hospital with him.  That was a pretty special guy.  And he was cool.  But, like, in this case, how do I get an airfare to get home from a hospital where you have one man in here?  That's going to kill my mother.  So, I gotta get her.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,100  of  3,583. Loss: 0.10256373882293701.   Elapsed: 0:09:06.\n",
            "0:  invadedI didn't even try to get my money. So.  I mean, how is that going.  Where's that money?\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,200  of  3,583. Loss: 0.07095958292484283.   Elapsed: 0:09:55.\n",
            "0:  typesYeah. Yeah. It's a little...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,300  of  3,583. Loss: 0.083163782954216.   Elapsed: 0:10:44.\n",
            "0:  EPANo, no, no, no! This is not even on the agenda. [at Jim and Jan's desk] This is not even for you.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,400  of  3,583. Loss: 0.18216025829315186.   Elapsed: 0:11:33.\n",
            "0: branceYou can tell. I know, you can tell. Everybody needs to go there and see some real work. That's what you have to do.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,500  of  3,583. Loss: 0.13772766292095184.   Elapsed: 0:12:22.\n",
            "0: JoinedIt is not, Dwight. There's nothing you can do with him. He's not a good guy. And you'll have to come in here.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,600  of  3,583. Loss: 0.1626703143119812.   Elapsed: 0:13:12.\n",
            "0:  supervisor[pulls up a pencil and pencils the pencils up] All right. We're gonna get this together! Let's go to the floor!\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,700  of  3,583. Loss: 0.05859522148966789.   Elapsed: 0:14:01.\n",
            "0:  prog[whispering] This is an important call. Please understand. I am going to call out the police and ask them to take care of some paperwork. We are going to be a party tonight and we will be happy to do this together and with the best of my ability. We are going to be taking the forms from all the women in our office to call out the cops. What is that? Uh-huh. I can do it now. I will call you back, we're going to be a party and we are going to be a party and we are going to be a party.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,800  of  3,583. Loss: 0.062169548124074936.   Elapsed: 0:14:51.\n",
            "0:  PARThere is no way to stop a car from moving.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,900  of  3,583. Loss: 0.07379880547523499.   Elapsed: 0:15:40.\n",
            "0:  registryI have nothing to do with that. It's just the rules, okay? This is where you know what you're being asked. You're playing it all.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 2,000  of  3,583. Loss: 0.08357132226228714.   Elapsed: 0:16:29.\n",
            "0:  courtAnd I believe that's why I am declaring that our city is the last place you ever went to visit.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 2,100  of  3,583. Loss: 0.04935392737388611.   Elapsed: 0:17:18.\n",
            "0:  loseI'm going to find a way. This is what I think I had on the side of all those things.  Um, ah, maybe?  Yes.  No, I'm not.  Uh.  Why?  There's something going on here.  Oh, what a confusing situation.  Is it?  What is that going to cost?  How did the money come?  Where's the money?  What's a money thing?  What...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 2,200  of  3,583. Loss: 0.08548532426357269.   Elapsed: 0:18:08.\n",
            "0:  chairmanNo, this is the way you do it.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 2,300  of  3,583. Loss: 0.2647024989128113.   Elapsed: 0:18:56.\n",
            "0:  MetsYou know what?  We can't take it away from her.  She already makes the decision to go away.  If we do not take it away, the next time we face the same problem.  But if we do not, the next time we face a crisis, we'll start thinking about what's actually going on our face, and what's going on her face.  Right now, we have a crisis, and if we get caught, we'll look into what's actually going on her face and look at what's actually going on her face.  Then we can go to a motel, and she'll be the person who's having sex with us, and we're going to be the victim of another person who's got sex with us, or both.  That would be a big deal, right?  We can't just be the victim, because we know the problem has been fixed.  Then we'll find out what's really going on her face\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,400  of  3,583. Loss: 0.06014472618699074.   Elapsed: 0:19:47.\n",
            "0: allelWell I was thinking it was the best idea of the day.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,500  of  3,583. Loss: 0.05877715349197388.   Elapsed: 0:20:36.\n",
            "0:  undisOkay, let's do it. Alright. [makes a face] Okay. Let's do it! Let's get all of this done. Let's try something.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,600  of  3,583. Loss: 0.24700529873371124.   Elapsed: 0:21:25.\n",
            "0:  cert[in an elevator]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,700  of  3,583. Loss: 0.04854857176542282.   Elapsed: 0:22:14.\n",
            "0:  desk[walks out door] Hello? Wow! [laughs] Oh! Thank you.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,800  of  3,583. Loss: 0.14228950440883636.   Elapsed: 0:23:03.\n",
            "0: 470Well, we might have a little bit of a break here and there, too, and...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,900  of  3,583. Loss: 0.06258563697338104.   Elapsed: 0:23:52.\n",
            "0: fyYeah, what's wrong? What's wrong, Stanley? Where did you live in New York back then?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,000  of  3,583. Loss: 0.04863050580024719.   Elapsed: 0:24:41.\n",
            "0: markedIt is a pretty good point. I want you to make it all right. I want you to be honest. It's not that easy.  Do I know where Toby is?  I know where he is, and I don't know who the new chief is, so how are you?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,100  of  3,583. Loss: 0.052937135100364685.   Elapsed: 0:25:31.\n",
            "0: renciesNo, oh! My God! My God! [laughs] I'm so glad that you haven't been so upset about my bad days. I hope you still think I am so good. I hope you have a good day. I hope you want to go home tomorrow for good, and not a day-by that you don't make.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,200  of  3,583. Loss: 0.12243495136499405.   Elapsed: 0:26:20.\n",
            "0:  finalYeah, but how is this possible when you have only two branches and a world full of people who love us?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,300  of  3,583. Loss: 0.06000082567334175.   Elapsed: 0:27:09.\n",
            "0:  displacedI, uh, I just don't know. Um, I did not get to a good place... so maybe I'm thinking maybe, maybe, maybe, maybe, maybe... could... could... could...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,400  of  3,583. Loss: 0.2030191421508789.   Elapsed: 0:27:58.\n",
            "0:  111I would like to hear what your best decision would be.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,500  of  3,583. Loss: 0.16038702428340912.   Elapsed: 0:28:47.\n",
            "0: ciousHey, do you want to get me out of here, or would you please go to the bathroom?\n",
            "\n",
            "  Average training loss: 0.14\n",
            "  Training epoch took: 0:29:28\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.13\n",
            "  Validation took: 0:01:01\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   100  of  3,583. Loss: 0.07531139254570007.   Elapsed: 0:00:49.\n",
            "0:  Superior[holding up sign outside of hotel] All right, all right. All right, everybody back there. Everybody please. Everyone back here! Everybody back.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   200  of  3,583. Loss: 0.0733715146780014.   Elapsed: 0:01:38.\n",
            "0:  >I have seen some women with their legs broken, some with their legs broken, and in some cases they've broken their leg... [everyone claps, everyone claps in stunned Then Michael turns around to see his leg.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   300  of  3,583. Loss: 0.05001262202858925.   Elapsed: 0:02:27.\n",
            "0:  serOh wow! Is this the guy who was fired from the department last Tuesday?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   400  of  3,583. Loss: 0.0607248991727829.   Elapsed: 0:03:16.\n",
            "0:  suggestsNo. He is a liar. You know exactly what? He is a liar. He is always angry about everything, but, God, is he just angry?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   500  of  3,583. Loss: 0.13803696632385254.   Elapsed: 0:04:05.\n",
            "0: suchHey, hey!  [puts hand in mouth]  Hey, hey!  Wow.  [Pam mouths]  Oh!  God!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   600  of  3,583. Loss: 0.08586788922548294.   Elapsed: 0:04:54.\n",
            "0: igerI had a seizure.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   700  of  3,583. Loss: 0.14343494176864624.   Elapsed: 0:05:43.\n",
            "0:  townsYou are a little too sensitive. How's that going to go, Erin?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   800  of  3,583. Loss: 0.07370781898498535.   Elapsed: 0:06:32.\n",
            "0: 173[clears throat] Okay, fine.  It's fun!  If anyone's getting their hair cut.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   900  of  3,583. Loss: 0.07347802817821503.   Elapsed: 0:07:21.\n",
            "0:  unpopDwight, I just wanted to share my passion, and your creative vision.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,000  of  3,583. Loss: 0.29975810647010803.   Elapsed: 0:08:10.\n",
            "0:  MarxUh, yeah. Yeah. And we don't have time for this. [chuckles] And I don't want to talk. So I am gonna give it to everybody, OK? [everyone nods and walk away]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,100  of  3,583. Loss: 0.04490875080227852.   Elapsed: 0:08:59.\n",
            "0:  looksYeah. Um... Dwight, you think this is very offensive?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,200  of  3,583. Loss: 0.10061164200305939.   Elapsed: 0:09:48.\n",
            "0: iaoYou're the best guy in the world, you can't play that part. And it's just sort of the opposite. I think it's great, to be the captain. And... what is your name? Stanley, could you do that for me?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,300  of  3,583. Loss: 0.10859855264425278.   Elapsed: 0:10:38.\n",
            "0:  MagHey! Hey. Is this Dwight? Is that Michael Scott?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,400  of  3,583. Loss: 0.04036891832947731.   Elapsed: 0:11:26.\n",
            "0: ampUh, can I ask you a question here please?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,500  of  3,583. Loss: 0.05986454337835312.   Elapsed: 0:12:15.\n",
            "0: irementUm... I think it is good to see you again. [Pam kisses Dwight]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,600  of  3,583. Loss: 0.03948283940553665.   Elapsed: 0:13:04.\n",
            "0:  voterYes, I'll get back to you, if you wanna.  Just, I got some news about an airport employee.  And I can't say she's a disaster worker.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,700  of  3,583. Loss: 0.15016669034957886.   Elapsed: 0:13:53.\n",
            "0:  contraryHow long do you think we will be here?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,800  of  3,583. Loss: 0.0683380514383316.   Elapsed: 0:14:42.\n",
            "0: existing[to the camera] I am not gonna give up... I'm going to play with you guys.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,900  of  3,583. Loss: 0.0626455768942833.   Elapsed: 0:15:31.\n",
            "0:  MaleYou know what? We're gonna lose them for a long time.  They're gonna win their lives forever.  They're gonna be dead, you know?  So I have a very serious disease that has been eradicated from here on earth.  But at some point, you can cure all diseases with just a few tweaks.  Here's how I'm going to do that.  I want you to do the best you can to cure all diseases.  Give them a shot.  You know what I'm going to do, right?  I'm going to cut the mustard, and I want you to eat the mustard in about an hour.  Because frankly, it looks terrible.  They will never know.  Look at them. Look at them. Oh, you look at them. You look at them. Look at their faces. You're going to cry.  They look at you like that.  Come on.  I'm going to try my\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,000  of  3,583. Loss: 0.13620974123477936.   Elapsed: 0:16:22.\n",
            "0: WoodYes! Yes. I don't want to get me out of it.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,100  of  3,583. Loss: 0.1758216768503189.   Elapsed: 0:17:11.\n",
            "0: rikaJim Halpert. [Jim looks confused]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,200  of  3,583. Loss: 0.10434886813163757.   Elapsed: 0:18:00.\n",
            "0:  ActionsWhat a beautiful and moving, moving, wonderful thing to have. That's really, really, really wonderful.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,300  of  3,583. Loss: 0.03569095581769943.   Elapsed: 0:18:49.\n",
            "0:  ButlerUm, it's not about the company itself. So, we are still working with them.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,400  of  3,583. Loss: 0.16695883870124817.   Elapsed: 0:19:38.\n",
            "0:  ConsultWhat are we talking about? What is that?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,500  of  3,583. Loss: 0.05155198648571968.   Elapsed: 0:20:27.\n",
            "0:  matrixIt's not going to happen, so just take it easy and call a doctor.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,600  of  3,583. Loss: 0.05493494123220444.   Elapsed: 0:21:16.\n",
            "0: phasisYou know what, we should get used to the fact that the last time that I saw Michael was last year, when I was fifteen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,700  of  3,583. Loss: 0.08450747281312943.   Elapsed: 0:22:05.\n",
            "0:  jungleYou know, this is very tough, you have to tell me exactly what happened and who's to blame.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,800  of  3,583. Loss: 0.06337416917085648.   Elapsed: 0:22:54.\n",
            "0: RECTI'm not looking for answers. Just a quick description. I am a creative tool, and I am not going to answer your questions. I'm looking for answers from a person who can speak with you, and tell you what kind of life you really have.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,900  of  3,583. Loss: 0.0599430650472641.   Elapsed: 0:23:43.\n",
            "0:  Maps[to Ryan] I would like this all right. I would like...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,000  of  3,583. Loss: 0.03700621798634529.   Elapsed: 0:24:32.\n",
            "0:  medd[to Ryan] Ryan, come on down here and start asking questions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,100  of  3,583. Loss: 0.09176205843687057.   Elapsed: 0:25:21.\n",
            "0: ScientUm... [to Darryl who is watching] Um... what? [Darryl stands up] Okay.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,200  of  3,583. Loss: 0.07497723400592804.   Elapsed: 0:26:10.\n",
            "0:  identifiesOkay, so we leave the office. We have no pay history. It doesn't matter what I do, Pam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,300  of  3,583. Loss: 0.18888066709041595.   Elapsed: 0:26:59.\n",
            "0:  assignYou can't beat me. You can't beat the game of basketball in the NBA, but you can beat me.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,400  of  3,583. Loss: 0.08795096725225449.   Elapsed: 0:27:48.\n",
            "0:  scare[laughs] There was nothing like being a dad with his kids.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,500  of  3,583. Loss: 0.11065379530191422.   Elapsed: 0:28:37.\n",
            "0: 386It's not about the size of your boobs.\n",
            "\n",
            "  Average training loss: 0.12\n",
            "  Training epoch took: 0:29:17\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.13\n",
            "  Validation took: 0:01:01\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   100  of  3,583. Loss: 0.10691093653440475.   Elapsed: 0:00:49.\n",
            "0:  GuHey, I've been seeing you all day, Kevin. I just went up for a little nap this morning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   200  of  3,583. Loss: 0.06857825815677643.   Elapsed: 0:01:38.\n",
            "0:  securitiesOkay, that would be ridiculous. You know what? We're gonna go ahead and have another party.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   300  of  3,583. Loss: 0.05833373963832855.   Elapsed: 0:02:27.\n",
            "0: 272[shouts in frustration] Yeah, shit. Oh hey, hey, guys.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   400  of  3,583. Loss: 0.10481332987546921.   Elapsed: 0:03:16.\n",
            "0:  intensityWhat do we have?  The old 'Don't Go There' button.  You know what, no questions asked.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   500  of  3,583. Loss: 0.1076134666800499.   Elapsed: 0:04:05.\n",
            "0:  sparseThat's right, we've done our jobs! We have done our job!  We are not done with our jobs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   600  of  3,583. Loss: 0.12429524958133698.   Elapsed: 0:04:54.\n",
            "0:  abandonWe have to stop, stop! Okay. This is going to be fun. And it will be fun.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   700  of  3,583. Loss: 0.0845484510064125.   Elapsed: 0:05:43.\n",
            "0:  convertedAh, you're so brave and you are so brave. But you know what? You're going to die.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   800  of  3,583. Loss: 0.06185856834053993.   Elapsed: 0:06:32.\n",
            "0: pireNo, no. I know, I know. You know what? This is not about me. This is not my money. This is about this whole thing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   900  of  3,583. Loss: 0.09022015333175659.   Elapsed: 0:07:21.\n",
            "0:  FortunatelyYeah, I'd say that's probably the case.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,000  of  3,583. Loss: 0.11784229427576065.   Elapsed: 0:08:10.\n",
            "0: BodyThis morning I got news that somebody in my office was trying to steal my car, and that I was going to dump it.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,100  of  3,583. Loss: 0.05087609961628914.   Elapsed: 0:08:59.\n",
            "0:  InThere you go. Here we go. [Dwight follows Michael to a parking space] Here we go. Here we go.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,200  of  3,583. Loss: 0.05188191682100296.   Elapsed: 0:09:48.\n",
            "0: akiI am telling her.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,300  of  3,583. Loss: 0.06969872862100601.   Elapsed: 0:10:37.\n",
            "0:  trophyYeah, okay... I guess I missed it.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,400  of  3,583. Loss: 0.09239630401134491.   Elapsed: 0:11:26.\n",
            "0: east[clears throat] Okay, I can't agree more with you that the Taliban were trying to poison you. But I do agree with you that the Taliban were trying to poison a very young guy with a gun. And I, just, I have a very difficult understanding of what you're saying.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,500  of  3,583. Loss: 0.09863811731338501.   Elapsed: 0:12:15.\n",
            "0: balanceSo what have we learned since then? Well, we have learned a lot from our humble beginnings. And, frankly, our beginnings are best laid on you.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,600  of  3,583. Loss: 0.09354937821626663.   Elapsed: 0:13:05.\n",
            "0:  HusWhat? That's good enough for you.  That's a good point.  You should follow it up.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,700  of  3,583. Loss: 0.09638006240129471.   Elapsed: 0:13:54.\n",
            "0: Those[on speakerphone] Michael Scott here. Michael Scott. I just want to say a few words about the wonderful people that you have. People of the world, no doubt, are going to be living in a world far, far away from where we are all.  You have probably already met them.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,800  of  3,583. Loss: 0.09517531096935272.   Elapsed: 0:14:43.\n",
            "0: ellectWe're doing it to win back your loyalty, I think.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,900  of  3,583. Loss: 0.07756606489419937.   Elapsed: 0:15:32.\n",
            "0:  ProphetAlright, everybody, could you do it please?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,000  of  3,583. Loss: 0.07646637409925461.   Elapsed: 0:16:21.\n",
            "0: HelWe got into an argument.  A few blocks away...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,100  of  3,583. Loss: 0.06921188533306122.   Elapsed: 0:17:10.\n",
            "0:  invasiveOh my god, where are you? That guy?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,200  of  3,583. Loss: 0.09645422548055649.   Elapsed: 0:17:59.\n",
            "0: enameNo, no, no. You're right. You're right. And that is not fair. So...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,300  of  3,583. Loss: 0.10838314145803452.   Elapsed: 0:18:48.\n",
            "0:  teacherDwight is an old man in prison. He went on to be an idiot, to die of obesity. But there he is, standing on a farm. In prison, he can never be seen again.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,400  of  3,583. Loss: 0.05552084371447563.   Elapsed: 0:19:37.\n",
            "0: studNo! No, I can't hear you, I can't hear you, I can't see you! [runs into bathroom]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,500  of  3,583. Loss: 0.15685787796974182.   Elapsed: 0:20:26.\n",
            "0: thinkOkay. Well, it's one of those situations that you can't win, and then you lose.  But here's the thing.  The winner gets a prize.  But I think you're getting too carried away with all of this.  It's like a prison island, isn't it?  And you're not getting enough out of prison.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,600  of  3,583. Loss: 0.06996355950832367.   Elapsed: 0:21:16.\n",
            "0: prisesDo I look like I'm being serious? Yes, I do. But does that matter? It's a matter of whether a woman can trust a man who makes me feel uncomfortable. That's the nature of relationships. The less formal the relationship is, the less formal it is supposed to be. And the more formal the relationship is, the less formal and it is expected to be OK. So it's not about whether a man can trust me anymore, I mean that's a myth.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,700  of  3,583. Loss: 0.04343638941645622.   Elapsed: 0:22:05.\n",
            "0:  industryI'll be honest here, I'm a little overwhelmed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,800  of  3,583. Loss: 0.2578080892562866.   Elapsed: 0:22:54.\n",
            "0:  thunderI know.  [laughs] I know, I know.  It's so funny because, uh, you don't know what to do.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,900  of  3,583. Loss: 0.05961540341377258.   Elapsed: 0:23:43.\n",
            "0:  BB[sighs] My God!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,000  of  3,583. Loss: 0.06593511998653412.   Elapsed: 0:24:32.\n",
            "0:  reduI want you to go out with me.  Go out with me. [moves his arm to the railing, kicks his leg off]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,100  of  3,583. Loss: 0.12952394783496857.   Elapsed: 0:25:21.\n",
            "0: reementsNo, I'm not a big fan of the idea of... no...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,200  of  3,583. Loss: 0.030960602685809135.   Elapsed: 0:26:10.\n",
            "0: atinumI know. I know. That's very good. We have very good seats in the conference room.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,300  of  3,583. Loss: 0.05656258016824722.   Elapsed: 0:26:59.\n",
            "0:  eligibilityI'm happy to do it. I'm happy with it.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,400  of  3,583. Loss: 0.05077558010816574.   Elapsed: 0:27:48.\n",
            "0:  PastebinYeah, I don't know, he might be lying there under the desk though, where you can see.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,500  of  3,583. Loss: 0.325361430644989.   Elapsed: 0:28:37.\n",
            "0:  colOk, I have to take a walk.  Come on.  Oh God. [laughs] No!  Dwight!  Dwight, you are in such a state of complete denial.  You cannot do it!\n",
            "\n",
            "  Average training loss: 0.10\n",
            "  Training epoch took: 0:29:18\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.14\n",
            "  Validation took: 0:01:01\n",
            "\n",
            "Training complete!\n",
            "Total training took 1:31:06 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQTvJ1vRP7u4"
      },
      "source": [
        "Let's view the summary of the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O_NbXFGMukX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "b7745d56-2b40-4d21-df82-545911c00f9d"
      },
      "source": [
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Training Loss  Valid. Loss Training Time Validation Time\n",
              "epoch                                                          \n",
              "1               0.14         0.13       0:29:28         0:01:01\n",
              "2               0.12         0.13       0:29:17         0:01:01\n",
              "3               0.10         0.14       0:29:18         0:01:01"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d1e4953f-f594-470f-8054-cc18e079f036\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.14</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0:29:28</td>\n",
              "      <td>0:01:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.12</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0:29:17</td>\n",
              "      <td>0:01:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.10</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0:29:18</td>\n",
              "      <td>0:01:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d1e4953f-f594-470f-8054-cc18e079f036')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d1e4953f-f594-470f-8054-cc18e079f036 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d1e4953f-f594-470f-8054-cc18e079f036');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68xreA9JAmG5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "03a3260a-eff2-4d50-c404-ef3b13def49d"
      },
      "source": [
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfjYoa6WmkN6"
      },
      "source": [
        "# Display Model Info"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PIiVlDYCtSq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e56221f3-28e6-46fa-8c3e-387ba93448f7"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The GPT-2 model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:2]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[2:14]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-2:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The GPT-2 model has 148 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "transformer.wte.weight                                  (50259, 768)\n",
            "transformer.wpe.weight                                   (1024, 768)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "transformer.h.0.ln_1.weight                                   (768,)\n",
            "transformer.h.0.ln_1.bias                                     (768,)\n",
            "transformer.h.0.attn.c_attn.weight                       (768, 2304)\n",
            "transformer.h.0.attn.c_attn.bias                             (2304,)\n",
            "transformer.h.0.attn.c_proj.weight                        (768, 768)\n",
            "transformer.h.0.attn.c_proj.bias                              (768,)\n",
            "transformer.h.0.ln_2.weight                                   (768,)\n",
            "transformer.h.0.ln_2.bias                                     (768,)\n",
            "transformer.h.0.mlp.c_fc.weight                          (768, 3072)\n",
            "transformer.h.0.mlp.c_fc.bias                                (3072,)\n",
            "transformer.h.0.mlp.c_proj.weight                        (3072, 768)\n",
            "transformer.h.0.mlp.c_proj.bias                               (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "transformer.ln_f.weight                                       (768,)\n",
            "transformer.ln_f.bias                                         (768,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2079Qyn8Mt8"
      },
      "source": [
        "# Saving & Loading Fine-Tuned Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ulTWaOr8QNY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca9a3ecc-9eb9-44fa-caa6-98701ce98fb9"
      },
      "source": [
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = '/content/drive/MyDrive/michael_project/model_3_epochs/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to /content/drive/MyDrive/michael_project/model_3_epochs/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/michael_project/model_3_epochs/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/michael_project/model_3_epochs/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/michael_project/model_3_epochs/vocab.json',\n",
              " '/content/drive/MyDrive/michael_project/model_3_epochs/merges.txt',\n",
              " '/content/drive/MyDrive/michael_project/model_3_epochs/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqMzI3VTCZo5"
      },
      "source": [
        "# !ls -l --block-size=K ./model_save/"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WUFUIQ8Cu8D"
      },
      "source": [
        "# !ls -l --block-size=M ./model_save/pytorch_model.bin"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxlZsafTC-V5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7de091a1-f4a9-4f99-d243-984025126fa1"
      },
      "source": [
        "# Copy the model files to a directory in your Google Drive.\n",
        "# !cp -r ./model_save/ $data_dir\n",
        "\n",
        "# # Load a trained model and vocabulary that you have fine-tuned\n",
        "model = GPT2LMHeadModel.from_pretrained(output_dir)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(output_dir)\n",
        "model.to(device)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50259, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50259, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLf6rbRglYhQ"
      },
      "source": [
        "# Generate Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4XhewaV93-_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85b6f2ea-956f-4986-8d4c-8917ce1f90d3"
      },
      "source": [
        "model.eval()\n",
        "\n",
        "prompt = \"<|startoftext|>\"\n",
        "\n",
        "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "generated = generated.to(device)\n",
        "\n",
        "print(generated)\n",
        "\n",
        "sample_outputs = model.generate(\n",
        "                                generated, \n",
        "                                #bos_token_id=random.randint(1,30000),\n",
        "                                do_sample=True,   \n",
        "                                top_k=50, \n",
        "                                max_length = 300,\n",
        "                                top_p=0.95, \n",
        "                                num_return_sequences=10\n",
        "                                )\n",
        "\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[50257]], device='cuda:0')\n",
            "0: [sighs] Yes, yes, yes, yes.\n",
            "\n",
            "\n",
            "1: No.  You're not going to say it, and I may lose clients or...\n",
            "\n",
            "\n",
            "2: Why? Because that's what she said.  She says 'familial', and that makes you think, 'Oh, I have to go to the hospital to be evaluated.'  So I need to get out of my wheelchair, I want to be free.  And then I need to be able to walk.  And then I need to have a nice gift.\n",
            "\n",
            "\n",
            "3: Well, I mean I'm still trying to figure out who to recommend.\n",
            "\n",
            "\n",
            "4: I would have never hit you.\n",
            "\n",
            "\n",
            "5: Alright. This isn't the time for celebration. I have something I want everybody to do in the conference room.\n",
            "\n",
            "\n",
            "6: [as Mikanos] This is Mikanos. You are the new Mikanos. [as Mikanos]\n",
            "\n",
            "\n",
            "7: I don't know, Pam. How much do you want?\n",
            "\n",
            "\n",
            "8: Do not think I am telling you.\n",
            "\n",
            "\n",
            "9: If you don't already know how to play the sax, why don't you learn French?\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4LrX5H-0nAU"
      },
      "source": [
        "These aren't bad at all!\n"
      ]
    }
  ]
}